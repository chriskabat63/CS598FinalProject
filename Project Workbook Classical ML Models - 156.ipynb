{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d1ehXFWM5aE"
   },
   "source": [
    "This notebook was created to support the data preparation required to support our CS 598 DLH project.  The paper we have chosen for the reproducibility project is:\n",
    "***Ensembling Classical Machine Learning and Deep Learning Approaches for Morbidity Identification from Clinical Notes ***\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv360l2IkNfO"
   },
   "source": [
    "The data cannot be shared publicly due to the agreements required to obtain the data so we are storing the data locally and not putting in GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow==2.10.*\n",
    "#pip install tensorflow-text==2.10.0\n",
    "#pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - All Features**\n",
    "\n",
    "![CML TFIDF All](images\\cml-tfidf-all.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - ExtraTreesClassifier Features**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-tfidf-extra.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - InfoGain Features**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-tfidf-infogain.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - SelectKBest Features**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-tfidf-selectkbest.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - Word Embeddings - No Stopwords**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-we-swno.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - Word Embeddings - Stopwords**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-we-swyes.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import torchtext\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, svm, naive_bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "# define data path\n",
    "DATA_PATH = './obesity_data/'\n",
    "RESULTS_PATH = './results/'\n",
    "MODELS_PATH = './models/'\n",
    "\n",
    "if os.path.exists(RESULTS_PATH) == False:\n",
    "    os.mkdir(RESULTS_PATH)\n",
    "if os.path.exists(MODELS_PATH) == False:\n",
    "    os.mkdir(MODELS_PATH)\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "#Download info for USE\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "all_docs_df = pd.read_pickle(DATA_PATH + '/alldocs_df.pkl')\n",
    "all_docs_df_ns = pd.read_pickle(DATA_PATH + '/alldocs_df_ns.pkl')\n",
    "all_annot_df = pd.read_pickle(DATA_PATH + '/allannot_df.pkl')\n",
    "all_df_expanded = pd.read_pickle(DATA_PATH + '/all_df_expanded.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.merge(all_docs_df,all_annot_df, on='id')\n",
    "all_df_ns = pd.merge(all_docs_df_ns,all_annot_df, on='id')\n",
    "\n",
    "disease_list = all_df['disease'].unique().tolist()\n",
    "#disease_list = ['Asthma']\n",
    "feature_list = ['All','ExtraTreeClassifier','SelectKBest','InfoGainAttributeVal']\n",
    "embedding_list = ['GloVe', 'FastText', 'USE']\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cols = ['Batch','Disease','Classifier','Feature', 'F1_MACRO', 'F1_MICRO', 'Total Run (secs)']\n",
    "\n",
    "def write_to_file(file, batch_name, disease, clfr, feature,f1_macro,f1_micro,runtime_sec):\n",
    "    #Pass TFIDF or Embeddings\n",
    "    \n",
    "    results_file = f'{RESULTS_PATH}CML_{file}_results.csv'\n",
    "\n",
    "    if os.path.exists(results_file):\n",
    "        results = pd.read_csv(results_file)\n",
    "    else:\n",
    "        results = pd.DataFrame(columns=result_cols)\n",
    "\n",
    "    result = pd.DataFrame(columns=result_cols,data=[[batch_name, disease,clfr,feature,f1_macro,f1_micro,runtime_sec]])\n",
    "    results = pd.concat([results,result])\n",
    "\n",
    "    #Save results - overwrite so we can see progress\n",
    "    results.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, entry in enumerate(all_df['tok_lem_text']):\n",
    "    Final_words = []\n",
    "    for word in entry:\n",
    "        Final_words.append(word)\n",
    "    all_df.loc[index, 'text_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, entry in enumerate(all_df_ns['tok_lem_text']):\n",
    "    Final_words = []\n",
    "    for word in entry:\n",
    "        Final_words.append(word)\n",
    "    all_df_ns.loc[index, 'text_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performSVM(Train_X_Tfidf, Test_X_Tfidf, y_train, y_test, feature):\n",
    "    start_time = time.time()\n",
    "    SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(Train_X_Tfidf, y_train)\n",
    "\n",
    "    predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "    end_time = time.time()\n",
    "    runtime_sec = end_time-start_time\n",
    "\n",
    "    #f1 = f1_score(y_test, predictions_SVM)\n",
    "    f1_macro = f1_score(y_test, predictions_SVM,average='macro')\n",
    "    f1_micro = f1_score(y_test, predictions_SVM,average='micro')\n",
    "\n",
    "    #print(\"SVM - \", disease, \": f1-score\", f1)\n",
    "    print(\"SVM - \", feature, disease, \": f1-macro\", f1_macro)\n",
    "    print(\"SVM - \", feature, disease, \": f1-micro\", f1_micro)\n",
    "    \n",
    "    write_to_file(file, batch_name, disease, \"SVM\", feature,f1_macro, f1_micro, runtime_sec)\n",
    "\n",
    "    return f1_macro, f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performKNN(Train_X_Tfidf, Test_X_Tfidf, y_train, y_test, feature):\n",
    "\n",
    "    start_time = time.time()\n",
    "    knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "    clf1 = knn1.fit(Train_X_Tfidf, y_train)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_KNN1 = clf1.predict(Test_X_Tfidf)\n",
    "    end_time = time.time()\n",
    "    runtime_sec1 = end_time-start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "    clf5 = knn5.fit(Train_X_Tfidf, y_train)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_KNN5 = clf5.predict(Test_X_Tfidf)\n",
    "    end_time = time.time()\n",
    "    runtime_sec5 = end_time-start_time\n",
    "\n",
    "\n",
    "    #auroc = roc_auc_score(truth, pred[:,1])\n",
    "    #f1 = f1_score(y_test, predictions_KNN)\n",
    "    f1_macro1 = f1_score(y_test, predictions_KNN1,average='macro')\n",
    "    f1_macro5 = f1_score(y_test, predictions_KNN5,average='macro')\n",
    "    f1_micro1 = f1_score(y_test, predictions_KNN1,average='micro')\n",
    "    f1_micro5 = f1_score(y_test, predictions_KNN5,average='micro')\n",
    "\n",
    "    #print(\"KNN - \", disease, \": f1-score\", f1)\n",
    "    print(\"KNN 1 k - \", feature, disease, \": f1-macro\", f1_macro1)\n",
    "    print(\"KNN 1 k - \", feature, disease, \": f1-micro\", f1_micro1)\n",
    "    print(\"KNN 5 k - \", feature, disease, \": f1-macro\", f1_macro5)\n",
    "    print(\"KNN 5 k - \", feature, disease, \": f1-micro\", f1_micro5)\n",
    "    \n",
    "    write_to_file(file, batch_name, disease, \"KNN n=1\", feature,f1_macro1,f1_micro1, runtime_sec1)\n",
    "    write_to_file(file, batch_name, disease, \"KNN n=5\", feature,f1_macro1,f1_micro1, runtime_sec5)\n",
    "\n",
    "    return f1_macro1, f1_micro1, f1_macro5, f1_micro5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performNB(Train_X_Tfidf, Test_X_Tfidf, y_train, y_test, feature):\n",
    "    start_time = time.time()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(Train_X_Tfidf)\n",
    "    \n",
    "    Naive = naive_bayes.MultinomialNB()\n",
    "    Naive.fit(scaler.transform(Train_X_Tfidf),y_train)\n",
    "\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "    end_time = time.time()\n",
    "    runtime_sec = end_time-start_time\n",
    "\n",
    "    #f1 = f1_score(y_test, predictions_NB)\n",
    "    f1_macro = f1_score(y_test, predictions_NB,average='macro')\n",
    "    f1_micro = f1_score(y_test, predictions_NB,average='micro')\n",
    "\n",
    "    #print(\"NB - \", disease, \": f1-score\", f1)\n",
    "    print(\"NB - \", feature, disease, \": f1-macro\", f1_macro)\n",
    "    print(\"NB - \", feature, disease, \": f1-micro\", f1_micro)\n",
    "\n",
    "    write_to_file(file, batch_name, disease, \"Naive Bayes\", feature,f1_macro, f1_micro, runtime_sec)\n",
    "    \n",
    "    return f1_macro, f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performRF(Train_X_Tfidf, Test_X_Tfidf, y_train, y_test, feature):\n",
    "    start_time = time.time()\n",
    "\n",
    "    classifier=RandomForestClassifier(n_estimators =400,criterion=\"entropy\",random_state =0)\n",
    "    classifier.fit(Train_X_Tfidf,y_train)\n",
    "\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_RF = classifier.predict(Test_X_Tfidf)\n",
    "    end_time = time.time()\n",
    "    runtime_sec = end_time-start_time\n",
    "\n",
    "    #f1 = f1_score(y_test, predictions_RF)\n",
    "    f1_macro = f1_score(y_test, predictions_RF,average='macro')\n",
    "    f1_micro = f1_score(y_test, predictions_RF,average='micro')\n",
    "\n",
    "    #print(\"RF - \", disease, \": f1-score\", f1)\n",
    "    print(\"RF - \", feature, disease, \": f1-macro\", f1_macro)\n",
    "    print(\"RF - \", feature, disease, \": f1-micro\", f1_micro)\n",
    "    \n",
    "    write_to_file(file, batch_name, disease, \"Random Forest\", feature,f1_macro, f1_micro, runtime_sec)\n",
    "\n",
    "    return f1_macro, f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_batch_GloVe(X_Train):\n",
    "    embedding_size_used = 300\n",
    "    vec = torchtext.vocab.GloVe(name='6B', dim=embedding_size_used)\n",
    "    \n",
    "    X =  np.zeros((X_Train.shape[0], embedding_size_used * len(X_Train.iloc[0])))\n",
    "    \n",
    "    for i in range(len(X_Train)):\n",
    "        vectors = vec.get_vecs_by_tokens(X_Train.iloc[i]).float().numpy()\n",
    "        \n",
    "        X[i,:] = vectors.flatten()\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_batch_FastText(X_Train):\n",
    "    embedding_size_used = 300\n",
    "    vec = torchtext.vocab.FastText()\n",
    "    \n",
    "    X =  np.zeros((X_Train.shape[0], embedding_size_used * len(X_Train.iloc[0])))\n",
    "    \n",
    "    for i in range(len(X_Train)):\n",
    "        vectors = vec.get_vecs_by_tokens(X_Train.iloc[i]).float().numpy()\n",
    "        \n",
    "        X[i,:] = vectors.flatten()\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_batch_USE(X_Train):\n",
    "    embedding_size_used = 512\n",
    "    \n",
    "    X =  np.zeros((X_Train.shape[0], embedding_size_used * len(X_Train.iloc[0])))\n",
    "    \n",
    "    for i in range(len(X_Train)):\n",
    "        tensor_flow_vectors = embed(X_Train.iloc[i])\n",
    "        array_vectors = tensor_flow_vectors.numpy()\n",
    "        \n",
    "        X[i,:] = array_vectors.flatten()\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateXTrainAndTest(X_train, X_test, Tfidf_vect):\n",
    "    X_train_values_list = Tfidf_vect.fit_transform(X_train).toarray()\n",
    "    X_training = pd.DataFrame(X_train_values_list, columns=Tfidf_vect.get_feature_names_out())\n",
    "    X_training = np.asarray(X_training, dtype=float)\n",
    "    X_training = torch.from_numpy(X_training).to(device)\n",
    "\n",
    "    X_test_values_list = Tfidf_vect.transform(X_test).toarray()\n",
    "    X_testing = pd.DataFrame(X_test_values_list, columns=Tfidf_vect.get_feature_names_out())\n",
    "    X_testing = np.asarray(X_testing, dtype=float)\n",
    "    X_testing = torch.from_numpy(X_testing).to(device)  \n",
    "    \n",
    "    return X_training, X_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def getVocab(X_train, y_train, feature, max_tokens):\n",
    " \n",
    "    ## Step 1: Determine the Initial Vocabulary\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    vocab = list(tokenizer.word_index.keys())\n",
    "\n",
    "    ## Step 2: Create term  matrix\n",
    "    vectors = tokenizer.texts_to_matrix(X_train, mode='count')\n",
    "\n",
    "    ## Do feature selection on term matrix (column headers are words)\n",
    "    X = vectors\n",
    "    y = y_train\n",
    "\n",
    "    ##Choose algorithm\n",
    "    if feature == 'SelectKBest':\n",
    "        selector = SelectKBest(score_func=f_classif, k=max_tokens).fit(X,y)\n",
    "    else: \n",
    "        if feature == 'InfoGainAttributeVal':\n",
    "            #This should be similar to the InfoGain?\n",
    "            selector = SelectKBest(score_func=mutual_info_classif, k=max_tokens).fit(X,y)\n",
    "        else:\n",
    "            #default to ExtraTreeClassifier\n",
    "            estimator = ExtraTreeClassifier(random_state = seed)\n",
    "            selector = SelectFromModel(estimator, max_features = max_tokens)\n",
    "            selector = selector.fit(X, y)\n",
    "\n",
    "    support_idx = selector.get_support(True)\n",
    "    tokenizer2 = Tokenizer()\n",
    "    tokenizer2.fit_on_texts([vocab[i-1].replace(\"'\",\"\") for i in support_idx])\n",
    "    new_vocab = list(tokenizer2.word_index.keys())\n",
    "\n",
    "    return new_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM -  All Asthma : f1-macro 0.609237775127399\n",
      "SVM -  All Asthma : f1-micro 0.9198113207547169\n",
      "KNN 1 k -  All Asthma : f1-macro 0.5623043623043623\n",
      "KNN 1 k -  All Asthma : f1-micro 0.8537735849056604\n",
      "KNN 5 k -  All Asthma : f1-macro 0.5846627483907081\n",
      "KNN 5 k -  All Asthma : f1-micro 0.9009433962264151\n",
      "NB -  All Asthma : f1-macro 0.6466666666666667\n",
      "NB -  All Asthma : f1-micro 0.9245283018867925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF -  All Asthma : f1-macro 0.6466666666666667\n",
      "RF -  All Asthma : f1-micro 0.9245283018867925\n",
      "Average SVM -  All : f1-micro 0.9198113207547169\n",
      "Average SVM -  All : f1-macro 0.609237775127399\n",
      "Average KNN 1 -  All : f1-micro 0.8537735849056604\n",
      "Average KNN 1 -  All : f1-macro 0.5623043623043623\n",
      "Average KNN 5 -  All : f1-micro 0.9009433962264151\n",
      "Average KNN 5 -  All : f1-macro 0.5846627483907081\n",
      "Average NB -  All : f1-micro 0.9245283018867925\n",
      "Average NB -  All : f1-macro 0.6466666666666667\n",
      "Average RF -  All : f1-micro 0.9245283018867925\n",
      "Average RF -  All : f1-macro 0.6466666666666667\n",
      "SVM -  ExtraTreeClassifier Asthma : f1-macro 0.6002514142049027\n",
      "SVM -  ExtraTreeClassifier Asthma : f1-micro 0.8726415094339622\n",
      "KNN 1 k -  ExtraTreeClassifier Asthma : f1-macro 0.605169591963429\n",
      "KNN 1 k -  ExtraTreeClassifier Asthma : f1-micro 0.8443396226415094\n",
      "KNN 5 k -  ExtraTreeClassifier Asthma : f1-macro 0.5484392214469336\n",
      "KNN 5 k -  ExtraTreeClassifier Asthma : f1-micro 0.8632075471698113\n",
      "NB -  ExtraTreeClassifier Asthma : f1-macro 0.4953623902158746\n",
      "NB -  ExtraTreeClassifier Asthma : f1-micro 0.8632075471698113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF -  ExtraTreeClassifier Asthma : f1-macro 0.5750286368843069\n",
      "RF -  ExtraTreeClassifier Asthma : f1-micro 0.8679245283018869\n",
      "Average SVM -  ExtraTreeClassifier : f1-micro 0.8962264150943395\n",
      "Average SVM -  ExtraTreeClassifier : f1-macro 0.6047445946661508\n",
      "Average KNN 1 -  ExtraTreeClassifier : f1-micro 0.8490566037735849\n",
      "Average KNN 1 -  ExtraTreeClassifier : f1-macro 0.5837369771338956\n",
      "Average KNN 5 -  ExtraTreeClassifier : f1-micro 0.8820754716981132\n",
      "Average KNN 5 -  ExtraTreeClassifier : f1-macro 0.5665509849188208\n",
      "Average NB -  ExtraTreeClassifier : f1-micro 0.8938679245283019\n",
      "Average NB -  ExtraTreeClassifier : f1-macro 0.5710145284412707\n",
      "Average RF -  ExtraTreeClassifier : f1-micro 0.8962264150943398\n",
      "Average RF -  ExtraTreeClassifier : f1-macro 0.6108476517754868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM -  SelectKBest Asthma : f1-macro 0.8923311325545962\n",
      "SVM -  SelectKBest Asthma : f1-micro 0.9433962264150944\n",
      "KNN 1 k -  SelectKBest Asthma : f1-macro 0.6372192513368984\n",
      "KNN 1 k -  SelectKBest Asthma : f1-micro 0.8490566037735849\n",
      "KNN 5 k -  SelectKBest Asthma : f1-macro 0.6290987076020091\n",
      "KNN 5 k -  SelectKBest Asthma : f1-micro 0.8537735849056604\n",
      "NB -  SelectKBest Asthma : f1-macro 0.5004776157422148\n",
      "NB -  SelectKBest Asthma : f1-micro 0.8254716981132075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF -  SelectKBest Asthma : f1-macro 0.8110853680270896\n",
      "RF -  SelectKBest Asthma : f1-micro 0.9056603773584906\n",
      "Average SVM -  SelectKBest : f1-micro 0.9119496855345912\n",
      "Average SVM -  SelectKBest : f1-macro 0.7006067739622993\n",
      "Average KNN 1 -  SelectKBest : f1-micro 0.8490566037735849\n",
      "Average KNN 1 -  SelectKBest : f1-macro 0.6015644018682299\n",
      "Average KNN 5 -  SelectKBest : f1-micro 0.8726415094339622\n",
      "Average KNN 5 -  SelectKBest : f1-macro 0.5874002258132169\n",
      "Average NB -  SelectKBest : f1-micro 0.8710691823899371\n",
      "Average NB -  SelectKBest : f1-macro 0.547502224208252\n",
      "Average RF -  SelectKBest : f1-micro 0.89937106918239\n",
      "Average RF -  SelectKBest : f1-macro 0.6775935571926878\n",
      "SVM -  InfoGainAttributeVal Asthma : f1-macro 0.8885223959080262\n",
      "SVM -  InfoGainAttributeVal Asthma : f1-micro 0.9481132075471698\n",
      "KNN 1 k -  InfoGainAttributeVal Asthma : f1-macro 0.6768122798717342\n",
      "KNN 1 k -  InfoGainAttributeVal Asthma : f1-micro 0.8632075471698113\n",
      "KNN 5 k -  InfoGainAttributeVal Asthma : f1-macro 0.6703349282296651\n",
      "KNN 5 k -  InfoGainAttributeVal Asthma : f1-micro 0.8773584905660378\n",
      "NB -  InfoGainAttributeVal Asthma : f1-macro 0.5953095173166076\n",
      "NB -  InfoGainAttributeVal Asthma : f1-micro 0.8679245283018869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF -  InfoGainAttributeVal Asthma : f1-macro 0.8479850853291266\n",
      "RF -  InfoGainAttributeVal Asthma : f1-micro 0.9292452830188679\n",
      "Average SVM -  InfoGainAttributeVal : f1-micro 0.9209905660377358\n",
      "Average SVM -  InfoGainAttributeVal : f1-macro 0.747585679448731\n",
      "Average KNN 1 -  InfoGainAttributeVal : f1-micro 0.8525943396226415\n",
      "Average KNN 1 -  InfoGainAttributeVal : f1-macro 0.620376371369106\n",
      "Average KNN 5 -  InfoGainAttributeVal : f1-micro 0.8738207547169812\n",
      "Average KNN 5 -  InfoGainAttributeVal : f1-macro 0.608133901417329\n",
      "Average NB -  InfoGainAttributeVal : f1-micro 0.8702830188679246\n",
      "Average NB -  InfoGainAttributeVal : f1-macro 0.5594540474853409\n",
      "Average RF -  InfoGainAttributeVal : f1-micro 0.9068396226415094\n",
      "Average RF -  InfoGainAttributeVal : f1-macro 0.7201914392267975\n"
     ]
    }
   ],
   "source": [
    "file = 'TFIDF'\n",
    "result_time = datetime.datetime.now()\n",
    "result_name = result_time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "batch_name = f'CML_tfidf_results_{result_name}'\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "Tfidf_vect = TfidfVectorizer(max_features=600)\n",
    "Tfidf_vect_NS = TfidfVectorizer(max_features = 600, stop_words = cachedStopWords)\n",
    "\n",
    "svm_f1_micro_scores = []\n",
    "svm_f1_macro_scores = []\n",
    "knn1_f1_micro_scores = []\n",
    "knn1_f1_macro_scores = []\n",
    "knn5_f1_micro_scores = []\n",
    "knn5_f1_macro_scores = []\n",
    "nb_f1_micro_scores = []\n",
    "nb_f1_macro_scores = []\n",
    "rf_f1_micro_scores = []\n",
    "rf_f1_macro_scores = []\n",
    "\n",
    "max_tokens = 600\n",
    "\n",
    "for _,feature in enumerate(feature_list):\n",
    "    for _,disease in enumerate(disease_list):\n",
    "        disease_data_df = all_df[all_df['disease'] == disease]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(disease_data_df['text_final'], disease_data_df['judgment'], test_size=0.20, shuffle=True)\n",
    "        \n",
    "        if feature != 'All':\n",
    "            vocab = getVocab(X_train,y_train, feature, max_tokens)\n",
    "            Tfidf_vect = TfidfVectorizer(max_features=max_tokens,vocabulary = vocab)\n",
    "        else:\n",
    "            Tfidf_vect = TfidfVectorizer(max_features=max_tokens)\n",
    "  \n",
    "        \n",
    "        X_train_values_list = Tfidf_vect.fit_transform(X_train).toarray()\n",
    "        X_training = pd.DataFrame(X_train_values_list, columns=Tfidf_vect.get_feature_names_out())\n",
    "        X_training = np.asarray(X_training, dtype=float)\n",
    "        X_training = torch.from_numpy(X_training).to(device)\n",
    "\n",
    "        X_test_values_list = Tfidf_vect.transform(X_test).toarray()\n",
    "        X_testing = pd.DataFrame(X_test_values_list, columns=Tfidf_vect.get_feature_names_out())\n",
    "        X_testing = np.asarray(X_testing, dtype=float)\n",
    "        X_testing = torch.from_numpy(X_testing).to(device)\n",
    "        \n",
    "        #tokens_to_use = X_training.shape[1]\n",
    "\n",
    "        Train_Y  = Encoder.fit_transform(y_train)\n",
    "        Test_Y  = Encoder.fit_transform(y_test)\n",
    "\n",
    "        svm_f1_macro, svm_f1_micro = performSVM(X_training, X_testing, Train_Y, Test_Y, feature)\n",
    "        svm_f1_macro_scores.append(svm_f1_macro)\n",
    "        svm_f1_micro_scores.append(svm_f1_micro)\n",
    "\n",
    "        knn_f1_macro1, knn_f1_micro1, knn_f1_macro5, knn_f1_micro5 = performKNN(X_training, X_testing, Train_Y, Test_Y, feature)\n",
    "        knn1_f1_macro_scores.append(knn_f1_macro1)\n",
    "        knn1_f1_micro_scores.append(knn_f1_micro1)\n",
    "        knn5_f1_macro_scores.append(knn_f1_macro5)\n",
    "        knn5_f1_micro_scores.append(knn_f1_micro5)\n",
    "\n",
    "        nb_f1_macro, nb_f1_micro = performNB(X_training, X_testing, Train_Y, Test_Y, feature)\n",
    "        nb_f1_macro_scores.append(nb_f1_macro)\n",
    "        nb_f1_micro_scores.append(nb_f1_micro)\n",
    "\n",
    "        rf_f1_macro, rf_f1_micro = performRF(X_training, X_testing, Train_Y, Test_Y, feature)\n",
    "        rf_f1_macro_scores.append(rf_f1_macro)\n",
    "        rf_f1_micro_scores.append(rf_f1_micro)\n",
    "        \n",
    "    print(\"Average SVM - \", feature, \": f1-micro\", mean(svm_f1_micro_scores))\n",
    "    print(\"Average SVM - \", feature, \": f1-macro\", mean(svm_f1_macro_scores))\n",
    "    \n",
    "    print(\"Average KNN 1 - \", feature, \": f1-micro\", mean(knn1_f1_micro_scores))\n",
    "    print(\"Average KNN 1 - \", feature, \": f1-macro\", mean(knn1_f1_macro_scores))\n",
    "    print(\"Average KNN 5 - \", feature, \": f1-micro\", mean(knn5_f1_micro_scores))\n",
    "    print(\"Average KNN 5 - \", feature, \": f1-macro\", mean(knn5_f1_macro_scores))\n",
    "    \n",
    "    print(\"Average NB - \", feature, \": f1-micro\", mean(nb_f1_micro_scores))\n",
    "    print(\"Average NB - \", feature, \": f1-macro\", mean(nb_f1_macro_scores))\n",
    "    \n",
    "    print(\"Average RF - \", feature, \": f1-micro\", mean(rf_f1_micro_scores))\n",
    "    print(\"Average RF - \", feature, \": f1-macro\", mean(rf_f1_macro_scores))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM -  GloVe Asthma : f1-macro 0.4642857142857143\n",
      "SVM -  GloVe Asthma : f1-micro 0.8666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 1 k -  GloVe Asthma : f1-macro 0.4642857142857143\n",
      "KNN 1 k -  GloVe Asthma : f1-micro 0.8666666666666667\n",
      "KNN 5 k -  GloVe Asthma : f1-macro 0.4642857142857143\n",
      "KNN 5 k -  GloVe Asthma : f1-micro 0.8666666666666667\n",
      "NB -  GloVe Asthma : f1-macro 0.524603836530442\n",
      "NB -  GloVe Asthma : f1-micro 0.8416666666666667\n",
      "RF -  GloVe Asthma : f1-macro 0.4642857142857143\n",
      "RF -  GloVe Asthma : f1-micro 0.8666666666666667\n",
      "Average SVM -  GloVe : f1-micro 0.8666666666666667\n",
      "Average SVM -  GloVe : f1-macro 0.4642857142857143\n",
      "Average KNN 1 -  GloVe : f1-micro 0.8666666666666667\n",
      "Average KNN 1 -  GloVe : f1-macro 0.4642857142857143\n",
      "Average KNN 5 -  GloVe : f1-micro 0.8666666666666667\n",
      "Average KNN 5 -  GloVe : f1-macro 0.4642857142857143\n",
      "Average NB -  GloVe : f1-micro 0.8416666666666667\n",
      "Average NB -  GloVe : f1-macro 0.524603836530442\n",
      "Average RF -  GloVe : f1-micro 0.8666666666666667\n",
      "Average RF -  GloVe : f1-macro 0.4642857142857143\n",
      "SVM -  FastText Asthma : f1-macro 0.47019867549668876\n",
      "SVM -  FastText Asthma : f1-micro 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 1 k -  FastText Asthma : f1-macro 0.47019867549668876\n",
      "KNN 1 k -  FastText Asthma : f1-micro 0.8875\n",
      "KNN 5 k -  FastText Asthma : f1-macro 0.47019867549668876\n",
      "KNN 5 k -  FastText Asthma : f1-micro 0.8875\n",
      "NB -  FastText Asthma : f1-macro 0.2671563923156113\n",
      "NB -  FastText Asthma : f1-micro 0.2708333333333333\n",
      "RF -  FastText Asthma : f1-macro 0.47019867549668876\n",
      "RF -  FastText Asthma : f1-micro 0.8875\n",
      "Average SVM -  FastText : f1-micro 0.8770833333333333\n",
      "Average SVM -  FastText : f1-macro 0.46724219489120156\n",
      "Average KNN 1 -  FastText : f1-micro 0.8770833333333333\n",
      "Average KNN 1 -  FastText : f1-macro 0.46724219489120156\n",
      "Average KNN 5 -  FastText : f1-micro 0.8770833333333333\n",
      "Average KNN 5 -  FastText : f1-macro 0.46724219489120156\n",
      "Average NB -  FastText : f1-micro 0.55625\n",
      "Average NB -  FastText : f1-macro 0.3958801144230266\n",
      "Average RF -  FastText : f1-micro 0.8770833333333333\n",
      "Average RF -  FastText : f1-macro 0.46724219489120156\n",
      "SVM -  USE Asthma : f1-macro 0.6133118506583699\n",
      "SVM -  USE Asthma : f1-micro 0.8791666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 1 k -  USE Asthma : f1-macro 0.636094361578335\n",
      "KNN 1 k -  USE Asthma : f1-micro 0.8208333333333333\n",
      "KNN 5 k -  USE Asthma : f1-macro 0.5066392577365408\n",
      "KNN 5 k -  USE Asthma : f1-micro 0.8458333333333333\n",
      "NB -  USE Asthma : f1-macro 0.4606741573033708\n",
      "NB -  USE Asthma : f1-micro 0.8541666666666666\n",
      "RF -  USE Asthma : f1-macro 0.6133118506583699\n",
      "RF -  USE Asthma : f1-micro 0.8791666666666667\n",
      "Average SVM -  USE : f1-micro 0.8777777777777778\n",
      "Average SVM -  USE : f1-macro 0.5159320801469243\n",
      "Average KNN 1 -  USE : f1-micro 0.8583333333333333\n",
      "Average KNN 1 -  USE : f1-macro 0.5235262504535794\n",
      "Average KNN 5 -  USE : f1-micro 0.8666666666666667\n",
      "Average KNN 5 -  USE : f1-macro 0.4803745491729813\n",
      "Average NB -  USE : f1-micro 0.6555555555555556\n",
      "Average NB -  USE : f1-macro 0.41747812871647466\n",
      "Average RF -  USE : f1-micro 0.8777777777777778\n",
      "Average RF -  USE : f1-macro 0.5159320801469243\n"
     ]
    }
   ],
   "source": [
    "file = 'Embeddings'\n",
    "result_time = datetime.datetime.now()\n",
    "result_name = result_time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "batch_name = f'CML_tfidf_results_{result_name}'\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "Tfidf_vect = TfidfVectorizer(max_features=600)\n",
    "Tfidf_vect_NS = TfidfVectorizer(max_features = 600, stop_words = cachedStopWords)\n",
    "\n",
    "svm_f1_micro_scores = []\n",
    "svm_f1_macro_scores = []\n",
    "knn1_f1_micro_scores = []\n",
    "knn1_f1_macro_scores = []\n",
    "knn5_f1_micro_scores = []\n",
    "knn5_f1_macro_scores = []\n",
    "nb_f1_micro_scores = []\n",
    "nb_f1_macro_scores = []\n",
    "rf_f1_micro_scores = []\n",
    "rf_f1_macro_scores = []\n",
    "\n",
    "max_tokens = 600\n",
    "\n",
    "for _, embedding in enumerate(embedding_list):\n",
    "    for _,disease in enumerate(disease_list):\n",
    "        disease_data_df = all_df_expanded [all_df_expanded ['disease'] == disease]\n",
    "\n",
    "        if embedding == 'GloVe':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(disease_data_df['vector_tokenized'], disease_data_df['judgment'], test_size=0.20, shuffle=True)\n",
    "            X_train = vectorize_batch_GloVe(X_train)\n",
    "            X_test = vectorize_batch_GloVe(X_test)\n",
    "        if embedding == 'FastText':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(disease_data_df['vector_tokenized'], disease_data_df['judgment'], test_size=0.20, shuffle=True)\n",
    "            X_train = vectorize_batch_FastText(X_train)\n",
    "            X_test = vectorize_batch_FastText(X_test)\n",
    "        if embedding == 'USE':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(disease_data_df['sentence_tokenized'], disease_data_df['judgment'], test_size=0.20, shuffle=True)\n",
    "            X_train = vectorize_batch_USE(X_train)\n",
    "            X_test = vectorize_batch_USE(X_test)\n",
    "\n",
    "        Train_Y  = Encoder.fit_transform(y_train)\n",
    "        Test_Y  = Encoder.fit_transform(y_test)\n",
    "\n",
    "        svm_f1_macro, svm_f1_micro = performSVM(X_train, X_test, Train_Y, Test_Y, embedding)\n",
    "        svm_f1_macro_scores.append(svm_f1_macro)\n",
    "        svm_f1_micro_scores.append(svm_f1_micro)\n",
    "\n",
    "        knn_f1_macro1, knn_f1_micro1, knn_f1_macro5, knn_f1_micro5 = performKNN(X_train, X_test, Train_Y, Test_Y, embedding)\n",
    "        knn1_f1_macro_scores.append(knn_f1_macro1)\n",
    "        knn1_f1_micro_scores.append(knn_f1_micro1)\n",
    "        knn5_f1_macro_scores.append(knn_f1_macro5)\n",
    "        knn5_f1_micro_scores.append(knn_f1_micro5)\n",
    "\n",
    "        nb_f1_macro, nb_f1_micro = performNB(X_train, X_test, Train_Y, Test_Y, embedding)\n",
    "        nb_f1_macro_scores.append(nb_f1_macro)\n",
    "        nb_f1_micro_scores.append(nb_f1_micro)\n",
    "\n",
    "        rf_f1_macro, rf_f1_micro = performRF(X_train, X_test, Train_Y, Test_Y, embedding)\n",
    "        rf_f1_macro_scores.append(rf_f1_macro)\n",
    "        rf_f1_micro_scores.append(rf_f1_micro)\n",
    "        \n",
    "    print(\"Average SVM - \", embedding, \": f1-micro\", mean(svm_f1_micro_scores))\n",
    "    print(\"Average SVM - \", embedding, \": f1-macro\", mean(svm_f1_macro_scores))\n",
    "\n",
    "    print(\"Average KNN 1 - \", embedding, \": f1-micro\", mean(knn1_f1_micro_scores))\n",
    "    print(\"Average KNN 1 - \", embedding, \": f1-macro\", mean(knn1_f1_macro_scores))\n",
    "    print(\"Average KNN 5 - \", embedding, \": f1-micro\", mean(knn5_f1_micro_scores))\n",
    "    print(\"Average KNN 5 - \", embedding, \": f1-macro\", mean(knn5_f1_macro_scores))\n",
    "\n",
    "    print(\"Average NB - \", embedding, \": f1-micro\", mean(nb_f1_micro_scores))\n",
    "    print(\"Average NB - \", embedding, \": f1-macro\", mean(nb_f1_macro_scores))\n",
    "\n",
    "    print(\"Average RF - \", embedding, \": f1-micro\", mean(rf_f1_micro_scores))\n",
    "    print(\"Average RF - \", embedding, \": f1-macro\", mean(rf_f1_macro_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "10pK5od01jfTHJyLN94dJxEube3sJszFm",
     "timestamp": 1678482671183
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
