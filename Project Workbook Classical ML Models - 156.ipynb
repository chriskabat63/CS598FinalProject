{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d1ehXFWM5aE"
   },
   "source": [
    "This notebook was created to support the data preparation required to support our CS 598 DLH project.  The paper we have chosen for the reproducibility project is:\n",
    "***Ensembling Classical Machine Learning and Deep Learning Approaches for Morbidity Identification from Clinical Notes ***\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv360l2IkNfO"
   },
   "source": [
    "The data cannot be shared publicly due to the agreements required to obtain the data so we are storing the data locally and not putting in GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1250,
     "status": "ok",
     "timestamp": 1679769727418,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "zyXrAo2dsJqf",
    "outputId": "0cc91c5b-f4de-41e2-f2bd-dd9ca70041a3"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = './obesity_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - All Features**\n",
    "\n",
    "![CML TFIDF All](images\\cml-tfidf-all.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - ExtraTreesClassifier Features**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-tfidf-extra.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - InfoGain Features**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-tfidf-infogain.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - SelectKBest Features**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-tfidf-selectkbest.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - Word Embeddings - No Stopwords**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-we-swno.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - Word Embeddings - Stopwords**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-we-swyes.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import torchtext\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, svm, naive_bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "# define data path\n",
    "DATA_PATH = './obesity_data/'\n",
    "RESULTS_PATH = './results/'\n",
    "MODELS_PATH = './models/'\n",
    "\n",
    "test_df = pd.read_pickle(DATA_PATH + '/test.pkl') \n",
    "train_df = pd.read_pickle(DATA_PATH + '/train.pkl') \n",
    "#corpus = pd.read_pickle(DATA_PATH + '/corpus.pkl')\n",
    "disease_list = test_df['disease'].unique().tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 600) #stop_words = cachedStopWords, max_features = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease</th>\n",
       "      <th>id</th>\n",
       "      <th>judgment</th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>no_punc_text</th>\n",
       "      <th>no_numerics_text</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>tok_lem_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>one_hot</th>\n",
       "      <th>vector_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490646815 | WMC | 31530471 | | 9629480 | 11/23...</td>\n",
       "      <td>490646815  WMC  31530471   9629480  11232006 1...</td>\n",
       "      <td>WMC         AM  ANEMIA  Signed  DIS  Admissi...</td>\n",
       "      <td>dr margarito nolting on at am code status the ...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>44</td>\n",
       "      <td>[50, 8437, 24327, 6, 17, 73, 159, 36, 1, 13, 2...</td>\n",
       "      <td>[dr, margarito, nolting, on, at, am, code, sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asthma</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490646815 | WMC | 31530471 | | 9629480 | 11/23...</td>\n",
       "      <td>490646815  WMC  31530471   9629480  11232006 1...</td>\n",
       "      <td>WMC         AM  ANEMIA  Signed  DIS  Admissi...</td>\n",
       "      <td>wmc am anemia signed dis admission date report...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>1429</td>\n",
       "      <td>[5794, 73, 387, 123, 138, 26, 53, 108, 36, 123...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHF</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490646815 | WMC | 31530471 | | 9629480 | 11/23...</td>\n",
       "      <td>490646815  WMC  31530471   9629480  11232006 1...</td>\n",
       "      <td>WMC         AM  ANEMIA  Signed  DIS  Admissi...</td>\n",
       "      <td>dr margarito nolting on at am code status the ...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>44</td>\n",
       "      <td>[50, 8437, 24327, 6, 17, 73, 159, 36, 1, 13, 2...</td>\n",
       "      <td>[dr, margarito, nolting, on, at, am, code, sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHF</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490646815 | WMC | 31530471 | | 9629480 | 11/23...</td>\n",
       "      <td>490646815  WMC  31530471   9629480  11232006 1...</td>\n",
       "      <td>WMC         AM  ANEMIA  Signed  DIS  Admissi...</td>\n",
       "      <td>wmc am anemia signed dis admission date report...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>1429</td>\n",
       "      <td>[5794, 73, 387, 123, 138, 26, 53, 108, 36, 123...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Depression</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490646815 | WMC | 31530471 | | 9629480 | 11/23...</td>\n",
       "      <td>490646815  WMC  31530471   9629480  11232006 1...</td>\n",
       "      <td>WMC         AM  ANEMIA  Signed  DIS  Admissi...</td>\n",
       "      <td>dr margarito nolting on at am code status the ...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>44</td>\n",
       "      <td>[50, 8437, 24327, 6, 17, 73, 159, 36, 1, 13, 2...</td>\n",
       "      <td>[dr, margarito, nolting, on, at, am, code, sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12636</th>\n",
       "      <td>CAD</td>\n",
       "      <td>175</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293423942 | ZH | 49231835 | | 153750 | 11/10/1...</td>\n",
       "      <td>293423942  ZH  49231835   153750  11101990 120...</td>\n",
       "      <td>ZH         AM  Discharge Summary  Unsigned  ...</td>\n",
       "      <td>zh am discharge summary unsigned dis admission...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "      <td>794</td>\n",
       "      <td>[6985, 73, 18, 126, 793, 138, 26, 53, 108, 36,...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12637</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>175</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293423942 | ZH | 49231835 | | 153750 | 11/10/1...</td>\n",
       "      <td>293423942  ZH  49231835   153750  11101990 120...</td>\n",
       "      <td>ZH         AM  Discharge Summary  Unsigned  ...</td>\n",
       "      <td>zh am discharge summary unsigned dis admission...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "      <td>794</td>\n",
       "      <td>[6985, 73, 18, 126, 793, 138, 26, 53, 108, 36,...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12638</th>\n",
       "      <td>Hypertension</td>\n",
       "      <td>175</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293423942 | ZH | 49231835 | | 153750 | 11/10/1...</td>\n",
       "      <td>293423942  ZH  49231835   153750  11101990 120...</td>\n",
       "      <td>ZH         AM  Discharge Summary  Unsigned  ...</td>\n",
       "      <td>zh am discharge summary unsigned dis admission...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "      <td>794</td>\n",
       "      <td>[6985, 73, 18, 126, 793, 138, 26, 53, 108, 36,...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12639</th>\n",
       "      <td>OA</td>\n",
       "      <td>175</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293423942 | ZH | 49231835 | | 153750 | 11/10/1...</td>\n",
       "      <td>293423942  ZH  49231835   153750  11101990 120...</td>\n",
       "      <td>ZH         AM  Discharge Summary  Unsigned  ...</td>\n",
       "      <td>zh am discharge summary unsigned dis admission...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "      <td>794</td>\n",
       "      <td>[6985, 73, 18, 126, 793, 138, 26, 53, 108, 36,...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12640</th>\n",
       "      <td>Obesity</td>\n",
       "      <td>175</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293423942 | ZH | 49231835 | | 153750 | 11/10/1...</td>\n",
       "      <td>293423942  ZH  49231835   153750  11101990 120...</td>\n",
       "      <td>ZH         AM  Discharge Summary  Unsigned  ...</td>\n",
       "      <td>zh am discharge summary unsigned dis admission...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "      <td>794</td>\n",
       "      <td>[6985, 73, 18, 126, 793, 138, 26, 53, 108, 36,...</td>\n",
       "      <td>[zh, am, discharge, summary, unsigned, dis, ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12641 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            disease   id  judgment  index  \\\n",
       "0            Asthma    1     False    NaN   \n",
       "1            Asthma    1     False    NaN   \n",
       "2               CHF    1      True    NaN   \n",
       "3               CHF    1      True    NaN   \n",
       "4        Depression    1     False    NaN   \n",
       "...             ...  ...       ...    ...   \n",
       "12636           CAD  175      True    0.0   \n",
       "12637      Diabetes  175     False    0.0   \n",
       "12638  Hypertension  175      True    0.0   \n",
       "12639            OA  175      True    0.0   \n",
       "12640       Obesity  175      True    0.0   \n",
       "\n",
       "                                                    text  \\\n",
       "0      490646815 | WMC | 31530471 | | 9629480 | 11/23...   \n",
       "1      490646815 | WMC | 31530471 | | 9629480 | 11/23...   \n",
       "2      490646815 | WMC | 31530471 | | 9629480 | 11/23...   \n",
       "3      490646815 | WMC | 31530471 | | 9629480 | 11/23...   \n",
       "4      490646815 | WMC | 31530471 | | 9629480 | 11/23...   \n",
       "...                                                  ...   \n",
       "12636  293423942 | ZH | 49231835 | | 153750 | 11/10/1...   \n",
       "12637  293423942 | ZH | 49231835 | | 153750 | 11/10/1...   \n",
       "12638  293423942 | ZH | 49231835 | | 153750 | 11/10/1...   \n",
       "12639  293423942 | ZH | 49231835 | | 153750 | 11/10/1...   \n",
       "12640  293423942 | ZH | 49231835 | | 153750 | 11/10/1...   \n",
       "\n",
       "                                            no_punc_text  \\\n",
       "0      490646815  WMC  31530471   9629480  11232006 1...   \n",
       "1      490646815  WMC  31530471   9629480  11232006 1...   \n",
       "2      490646815  WMC  31530471   9629480  11232006 1...   \n",
       "3      490646815  WMC  31530471   9629480  11232006 1...   \n",
       "4      490646815  WMC  31530471   9629480  11232006 1...   \n",
       "...                                                  ...   \n",
       "12636  293423942  ZH  49231835   153750  11101990 120...   \n",
       "12637  293423942  ZH  49231835   153750  11101990 120...   \n",
       "12638  293423942  ZH  49231835   153750  11101990 120...   \n",
       "12639  293423942  ZH  49231835   153750  11101990 120...   \n",
       "12640  293423942  ZH  49231835   153750  11101990 120...   \n",
       "\n",
       "                                        no_numerics_text  \\\n",
       "0        WMC         AM  ANEMIA  Signed  DIS  Admissi...   \n",
       "1        WMC         AM  ANEMIA  Signed  DIS  Admissi...   \n",
       "2        WMC         AM  ANEMIA  Signed  DIS  Admissi...   \n",
       "3        WMC         AM  ANEMIA  Signed  DIS  Admissi...   \n",
       "4        WMC         AM  ANEMIA  Signed  DIS  Admissi...   \n",
       "...                                                  ...   \n",
       "12636    ZH         AM  Discharge Summary  Unsigned  ...   \n",
       "12637    ZH         AM  Discharge Summary  Unsigned  ...   \n",
       "12638    ZH         AM  Discharge Summary  Unsigned  ...   \n",
       "12639    ZH         AM  Discharge Summary  Unsigned  ...   \n",
       "12640    ZH         AM  Discharge Summary  Unsigned  ...   \n",
       "\n",
       "                                              lower_text  \\\n",
       "0      dr margarito nolting on at am code status the ...   \n",
       "1      wmc am anemia signed dis admission date report...   \n",
       "2      dr margarito nolting on at am code status the ...   \n",
       "3      wmc am anemia signed dis admission date report...   \n",
       "4      dr margarito nolting on at am code status the ...   \n",
       "...                                                  ...   \n",
       "12636  zh am discharge summary unsigned dis admission...   \n",
       "12637  zh am discharge summary unsigned dis admission...   \n",
       "12638  zh am discharge summary unsigned dis admission...   \n",
       "12639  zh am discharge summary unsigned dis admission...   \n",
       "12640  zh am discharge summary unsigned dis admission...   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "0      [wmc, am, anemia, signed, dis, admission, date...   \n",
       "1      [wmc, am, anemia, signed, dis, admission, date...   \n",
       "2      [wmc, am, anemia, signed, dis, admission, date...   \n",
       "3      [wmc, am, anemia, signed, dis, admission, date...   \n",
       "4      [wmc, am, anemia, signed, dis, admission, date...   \n",
       "...                                                  ...   \n",
       "12636  [zh, am, discharge, summary, unsigned, dis, ad...   \n",
       "12637  [zh, am, discharge, summary, unsigned, dis, ad...   \n",
       "12638  [zh, am, discharge, summary, unsigned, dis, ad...   \n",
       "12639  [zh, am, discharge, summary, unsigned, dis, ad...   \n",
       "12640  [zh, am, discharge, summary, unsigned, dis, ad...   \n",
       "\n",
       "                                            tok_lem_text  word_count  \\\n",
       "0      [wmc, am, anemia, signed, dis, admission, date...          44   \n",
       "1      [wmc, am, anemia, signed, dis, admission, date...        1429   \n",
       "2      [wmc, am, anemia, signed, dis, admission, date...          44   \n",
       "3      [wmc, am, anemia, signed, dis, admission, date...        1429   \n",
       "4      [wmc, am, anemia, signed, dis, admission, date...          44   \n",
       "...                                                  ...         ...   \n",
       "12636  [zh, am, discharge, summary, unsigned, dis, ad...         794   \n",
       "12637  [zh, am, discharge, summary, unsigned, dis, ad...         794   \n",
       "12638  [zh, am, discharge, summary, unsigned, dis, ad...         794   \n",
       "12639  [zh, am, discharge, summary, unsigned, dis, ad...         794   \n",
       "12640  [zh, am, discharge, summary, unsigned, dis, ad...         794   \n",
       "\n",
       "                                                 one_hot  \\\n",
       "0      [50, 8437, 24327, 6, 17, 73, 159, 36, 1, 13, 2...   \n",
       "1      [5794, 73, 387, 123, 138, 26, 53, 108, 36, 123...   \n",
       "2      [50, 8437, 24327, 6, 17, 73, 159, 36, 1, 13, 2...   \n",
       "3      [5794, 73, 387, 123, 138, 26, 53, 108, 36, 123...   \n",
       "4      [50, 8437, 24327, 6, 17, 73, 159, 36, 1, 13, 2...   \n",
       "...                                                  ...   \n",
       "12636  [6985, 73, 18, 126, 793, 138, 26, 53, 108, 36,...   \n",
       "12637  [6985, 73, 18, 126, 793, 138, 26, 53, 108, 36,...   \n",
       "12638  [6985, 73, 18, 126, 793, 138, 26, 53, 108, 36,...   \n",
       "12639  [6985, 73, 18, 126, 793, 138, 26, 53, 108, 36,...   \n",
       "12640  [6985, 73, 18, 126, 793, 138, 26, 53, 108, 36,...   \n",
       "\n",
       "                                        vector_tokenized  \n",
       "0      [dr, margarito, nolting, on, at, am, code, sta...  \n",
       "1      [wmc, am, anemia, signed, dis, admission, date...  \n",
       "2      [dr, margarito, nolting, on, at, am, code, sta...  \n",
       "3      [wmc, am, anemia, signed, dis, admission, date...  \n",
       "4      [dr, margarito, nolting, on, at, am, code, sta...  \n",
       "...                                                  ...  \n",
       "12636  [zh, am, discharge, summary, unsigned, dis, ad...  \n",
       "12637  [zh, am, discharge, summary, unsigned, dis, ad...  \n",
       "12638  [zh, am, discharge, summary, unsigned, dis, ad...  \n",
       "12639  [zh, am, discharge, summary, unsigned, dis, ad...  \n",
       "12640  [zh, am, discharge, summary, unsigned, dis, ad...  \n",
       "\n",
       "[12641 rows x 13 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [12641, 11190]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2417\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2417\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2419\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2420\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2421\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2422\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:378\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 378\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    335\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [12641, 11190]"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m Encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 2\u001b[0m Train_Y  \u001b[38;5;241m=\u001b[39m Encoder\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43my_train\u001b[49m)\n\u001b[0;32m      3\u001b[0m Test_Y  \u001b[38;5;241m=\u001b[39m Encoder\u001b[38;5;241m.\u001b[39mfit_transform(y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y  = Encoder.fit_transform(y_train)\n",
    "Test_Y  = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int32' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m Tfidf_vect \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m Train_X_Tfidf \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTrain_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m Test_X_Tfidf \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(Test_X)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2077\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"Learn vocabulary and idf, return document-term matrix.\u001b[39;00m\n\u001b[0;32m   2059\u001b[0m \n\u001b[0;32m   2060\u001b[0m \u001b[38;5;124;03mThis is equivalent to fit followed by transform, but more efficiently\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;124;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   2075\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m-> 2077\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2079\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2080\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1322\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1323\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1324\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1325\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1326\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1327\u001b[0m             )\n\u001b[0;32m   1328\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1330\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1333\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1200\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1201\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1202\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1203\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:71\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[1;32m---> 71\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.int32' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Train_X_Tfidf = vectorizer.fit_transform(Train_X)\n",
    "Test_X_Tfidf = vectorizer.fit_transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Tfidf_vect.vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://link.springer.com/article/10.1007/BF00994018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf, Train_Y)\n",
    "\n",
    "# predict labels\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "# get the accuracy\n",
    "print(\"Accuracy: \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbours (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://link.springer.com/article/10.1007/BF00153759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1302.4964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://link.springer.com/article/10.1023/A:1010933404324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://onlinelibrary.wiley.com/doi/10.1002/rsa.3240050207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# J-48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://server3.eca.ir/isi/forum/Programs%20for%20Machine%20Learning.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# J-Rip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sciencedirect.com/science/article/pii/B9781558603776500232?via%3Dihub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "10pK5od01jfTHJyLN94dJxEube3sJszFm",
     "timestamp": 1678482671183
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
