{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d1ehXFWM5aE"
   },
   "source": [
    "This notebook was created to support the data preparation required to support our CS 598 DLH project.  The paper we have chosen for the reproducibility project is:\n",
    "***Ensembling Classical Machine Learning and Deep Learning Approaches for Morbidity Identification from Clinical Notes ***\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv360l2IkNfO"
   },
   "source": [
    "The data cannot be shared publicly due to the agreements required to obtain the data so we are storing the data locally and not putting in GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1250,
     "status": "ok",
     "timestamp": 1679769727418,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "zyXrAo2dsJqf",
    "outputId": "0cc91c5b-f4de-41e2-f2bd-dd9ca70041a3"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = './obesity_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - All Features**\n",
    "\n",
    "![CML TFIDF All](images\\cml-tfidf-all.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - ExtraTreesClassifier Features**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-tfidf-extra.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - InfoGain Features**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-tfidf-infogain.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - TF-IDF - SelectKBest Features**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-tfidf-selectkbest.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - Word Embeddings - No Stopwords**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-we-swno.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Machine Learning - Word Embeddings - Stopwords**\n",
    "\n",
    "![CML TFIDF ExtraTrees](images\\cml-we-swyes.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import torchtext\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, svm, naive_bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "# define data path\n",
    "DATA_PATH = './obesity_data/'\n",
    "RESULTS_PATH = './results/'\n",
    "MODELS_PATH = './models/'\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "all_docs_df = pd.read_pickle(DATA_PATH + '/alldocs_df.pkl')\n",
    "all_docs_df_ns = pd.read_pickle(DATA_PATH + '/alldocs_df_ns.pkl')\n",
    "all_annot_df = pd.read_pickle(DATA_PATH + '/alannot_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asthma', 'CHF', 'Depression', 'Diabetes', 'Gallstones', 'Gout', 'Hypercholesterolemia', 'Hypertriglyceridemia', 'OA', 'OSA', 'Obesity', 'CAD', 'Hypertension', 'PVD', 'Venous Insufficiency', 'GERD']\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.merge(all_docs_df,all_annot_df, on='id')\n",
    "all_df_ns = pd.merge(all_docs_df_ns,all_annot_df, on='id')\n",
    "\n",
    "disease_list = all_df['disease'].unique().tolist()\n",
    "\n",
    "print(disease_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, entry in enumerate(all_df['tok_lem_text']):\n",
    "    Final_words = []\n",
    "    for word in entry:\n",
    "        Final_words.append(word)\n",
    "    all_df.loc[index, 'text_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, entry in enumerate(all_df_ns['tok_lem_text']):\n",
    "    Final_words = []\n",
    "    for word in entry:\n",
    "        Final_words.append(word)\n",
    "    all_df_ns.loc[index, 'text_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = all_df[all_df['disease'] == 'CHF']\n",
    "#print(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_df['text_final'], all_df['judgment'], test_size=0.20, shuffle=True)\n",
    "X_train_ns, X_test_ns, y_train_ns, y_test_ns = train_test_split(all_df_ns['text_final'], all_df_ns['judgment'], test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "\n",
    "Train_Y  = Encoder.fit_transform(y_train)\n",
    "Test_Y  = Encoder.fit_transform(y_test)\n",
    "\n",
    "Train_Y_NS  = Encoder.fit_transform(y_train_ns)\n",
    "Test_Y_NS = Encoder.fit_transform(y_test_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=600)\n",
    "Tfidf_vect_NS = TfidfVectorizer(max_features = 600, stop_words = cachedStopWords)\n",
    "\n",
    "Train_X_Tfidf = Tfidf_vect.fit_transform(X_train)\n",
    "Test_X_Tfidf = Tfidf_vect.fit_transform(X_test)\n",
    "\n",
    "Train_X_Tfidf_NS = Tfidf_vect_NS.fit_transform(X_train_ns)\n",
    "Test_X_Tfidf_NS = Tfidf_vect_NS.fit_transform(X_test_ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://link.springer.com/article/10.1007/BF00994018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy:  72.41379310344827\n",
      "0.8058252427184466\n",
      "0.6648173832639852\n",
      "0.7241379310344829\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the SVM classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf, y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy: \",accuracy_score(predictions_SVM, y_test)*100)\n",
    "\n",
    "f1 = f1_score(y_test, predictions_SVM)\n",
    "f1_macro = f1_score(y_test, predictions_SVM,average='macro')\n",
    "f1_micro = f1_score(y_test, predictions_SVM,average='micro')\n",
    "\n",
    "print(f1)\n",
    "print(f1_macro)\n",
    "print(f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the SVM classifier\n",
    "SVM_NS = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM_NS.fit(Train_X_Tfidf_NS, y_train_ns)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM_NS = SVM.predict(Test_X_Tfidf_NS)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM NS Accuracy: \",accuracy_score(predictions_SVM_NS, y_test_ns)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbours (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://link.springer.com/article/10.1007/BF00153759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Accuracy:  64.82758620689654\n",
      "0.7733333333333333\n",
      "0.49435897435897436\n",
      "0.6482758620689655\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "clf = knn.fit(Train_X_Tfidf, y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_KNN = clf.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"kNN Accuracy: \",accuracy_score(predictions_KNN, y_test)*100)\n",
    "\n",
    "#print(predictions_KNN)\n",
    "\n",
    "#auroc = roc_auc_score(truth, pred[:,1])\n",
    "f1 = f1_score(y_test, predictions_KNN)\n",
    "f1_macro = f1_score(y_test, predictions_KNN,average='macro')\n",
    "f1_micro = f1_score(y_test, predictions_KNN,average='micro')\n",
    "\n",
    "print(f1)\n",
    "print(f1_macro)\n",
    "print(f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the KNN classifier\n",
    "knn_ns = KNeighborsClassifier(n_neighbors=7)\n",
    "clf_ns = knn_ns.fit(Train_X_Tfidf_NS, y_train_ns)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_KNN_NS = clf_ns.predict(Test_X_Tfidf_NS)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"kNN NS Accuracy: \",accuracy_score(predictions_KNN_NS, y_test_ns)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1302.4964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  68.96551724137932\n",
      "0.8034934497816593\n",
      "0.5328942658744362\n",
      "0.6896551724137931\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, y_test)*100)\n",
    "\n",
    "f1 = f1_score(y_test, predictions_NB)\n",
    "f1_macro = f1_score(y_test, predictions_NB,average='macro')\n",
    "f1_micro = f1_score(y_test, predictions_NB,average='micro')\n",
    "\n",
    "print(f1)\n",
    "print(f1_macro)\n",
    "print(f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive_NS = naive_bayes.MultinomialNB()\n",
    "Naive_NS.fit(Train_X_Tfidf_NS, y_train_ns)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB_NS = Naive.predict(Test_X_Tfidf_NS)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes NS Accuracy Score -> \",accuracy_score(predictions_NB_NS, y_test_ns)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://link.springer.com/article/10.1023/A:1010933404324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score ->  73.79310344827587\n",
      "0.8362068965517241\n",
      "0.5905172413793103\n",
      "0.7379310344827587\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the RF classifier\n",
    "classifier=RandomForestClassifier(n_estimators =400,criterion=\"entropy\",random_state =0)\n",
    "classifier.fit(Train_X_Tfidf,y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_RF = classifier.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Random Forest Accuracy Score -> \",accuracy_score(predictions_RF, y_test)*100)\n",
    "\n",
    "f1 = f1_score(y_test, predictions_RF)\n",
    "f1_macro = f1_score(y_test, predictions_RF,average='macro')\n",
    "f1_micro = f1_score(y_test, predictions_RF,average='micro')\n",
    "\n",
    "print(f1)\n",
    "print(f1_macro)\n",
    "print(f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the RF classifier\n",
    "classifier_ns = RandomForestClassifier(n_estimators = 400, criterion = \"entropy\", random_state = 0)\n",
    "classifier_ns.fit(Train_X_Tfidf_NS, y_train_ns)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_RF_NS = classifier_ns.predict(Test_X_Tfidf_NS)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Random Forest NS Accuracy Score -> \",accuracy_score(predictions_RF_NS, y_test_ns)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://onlinelibrary.wiley.com/doi/10.1002/rsa.3240050207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "10pK5od01jfTHJyLN94dJxEube3sJszFm",
     "timestamp": 1678482671183
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
