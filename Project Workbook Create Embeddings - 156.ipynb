{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3d1ehXFWM5aE"
   },
   "source": [
    "Title:  Project Workbook Create Embeddings\n",
    "\n",
    "Authors:  Matthew Lopes and Chris Kabat\n",
    "\n",
    "This notebook was created to allow for word/sentence embeddings to be created to support our CS 598 DLH project. We do not actually create the embeddings in this notebook to avoid saving large files, but prepare the data for the creation of them. The paper we have chosen for the reproducibility project is:\n",
    "***Ensembling Classical Machine Learning and Deep Learning Approaches for Morbidity Identification from Clinical Notes ***\n",
    "\n",
    "Abstract:  The main goal of the paper is to extract Morbidity from clinical notes.  The idea was to use a combination of classical and deep learning methods to determine the best approach for classifying these notes in one or more of 16 morbidity conditions.  These models used a combination of NLP techniques including embeddings and bag of words implementations.  It also measured the effect including of stop words.  Lastly, it used ensemble techniques to tie together a number of the classical and deep learning models to provide the most accurate results.\n",
    "\n",
    "The data cannot be shared publicly due to the agreements required to obtain the data so we are storing the data locally and not putting in GitHub.\n",
    "\n",
    "We are only creating embeddings for data that includes stop words.\n",
    "\n",
    "In this workbook, we are taking the following steps:\n",
    "\n",
    "* Split large documents into smaller sections (left and right)\n",
    "* Create a one-hot encoding representation of the text\n",
    "* Create a tokenized and padded representation of the words and sentences\n",
    "\n",
    " First we load the required libraries and create a new fields that are the count of words and sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1250,
     "status": "ok",
     "timestamp": 1679769727418,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "zyXrAo2dsJqf",
    "outputId": "0cc91c5b-f4de-41e2-f2bd-dd9ca70041a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentences: 380\n",
      "   Min        Mean   Max         Std  MeanPlusStd\n",
      "0  113  973.840787  3748  441.912616       1416.0\n",
      "1  113  973.840787  3748  441.912616       1416.0\n",
      "Max Tokens: 1416\n",
      "All: 156 out of 1118\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = './obesity_data/'\n",
    "\n",
    "#Field to tokenize on\n",
    "#tokenize_field = 'lower_text'\n",
    "tokenize_field = 'tok_lem_text'\n",
    "#tokenize_field = 'word_tokenized'\n",
    "isTokenized = True\n",
    "\n",
    "#Don't need to do this for the one with no stop words\n",
    "alldocs_df = pd.read_pickle(DATA_PATH + '/alldocs_df.pkl')\n",
    "allannot_df= pd.read_pickle(DATA_PATH + '/allannot_df.pkl')\n",
    "\n",
    "\n",
    "alldocs_df['sentence_count'] = alldocs_df['sentence_tokenized'].apply(lambda x: len(x))\n",
    "sentence_max = np.max(alldocs_df['sentence_count'])\n",
    "print('Max Sentences:', sentence_max)\n",
    "\n",
    "if isTokenized:\n",
    "    alldocs_df['word_count'] = alldocs_df[tokenize_field].apply(lambda x: len(x))\n",
    "    alldocs_df['word_count'] = alldocs_df[tokenize_field].apply(lambda x: len(x))\n",
    "else:\n",
    "    alldocs_df['word_count'] = alldocs_df[tokenize_field].apply(lambda x: len(x.split()))\n",
    "    alldocs_df['word_count'] = alldocs_df[tokenize_field].apply(lambda x: len(x.split()))\n",
    "\n",
    "df_print = pd.DataFrame()\n",
    "df_print['Min'] = [np.min(alldocs_df['word_count']), np.min(alldocs_df['word_count'])]\n",
    "df_print['Mean'] = [np.mean(alldocs_df['word_count']), np.mean(alldocs_df['word_count'])]\n",
    "df_print['Max'] = [np.max(alldocs_df['word_count']), np.max(alldocs_df['word_count'])]\n",
    "df_print['Std'] = [np.std(alldocs_df['word_count']), np.std(alldocs_df['word_count'])]\n",
    "df_print['MeanPlusStd'] = round(df_print['Mean'] + df_print['Std'],0)\n",
    "token_max = int(round(np.max(df_print['MeanPlusStd']),0))\n",
    "\n",
    "print(df_print)\n",
    "print('Max Tokens:',token_max)\n",
    "print('All:', sum(alldocs_df['word_count'] > token_max), \"out of\", len(alldocs_df))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to split these larger text blocks into 2 notes of size max_token or below.  Note, there are 4 notes (1 in test and 3 in train) that are bigger than 2 times x tokens.  In those cases we are only taking the top and bottom of the document (left and right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 0 out of 1274\n"
     ]
    }
   ],
   "source": [
    "alldocs_df_ok = alldocs_df[alldocs_df['word_count'] <= token_max].copy()\n",
    "alldocs_df_large_left = alldocs_df[alldocs_df['word_count'] > token_max].copy()\n",
    "alldocs_df_large_right = alldocs_df[alldocs_df['word_count'] > token_max].copy()\n",
    "\n",
    "#Get the right words and the left words and then concatenate all 3 and recacluate \n",
    "if isTokenized:\n",
    "    #alldocs_df_large_left[tokenize_field] = alldocs_df_large_left[tokenize_field].apply(lambda x: [word for word in x[:(token_max-1)]])\n",
    "    #alldocs_df_large_right[tokenize_field] = alldocs_df_large_right[tokenize_field].apply(lambda x: [word for word in x[token_max:(2*token_max)]])\n",
    "    alldocs_df_large_left[tokenize_field] = alldocs_df_large_left[tokenize_field].apply(lambda x: [word for word in x[:(token_max)]])\n",
    "    alldocs_df_large_right[tokenize_field] = alldocs_df_large_right[tokenize_field].apply(lambda x: [word for word in x[(len(x)-token_max):len(x)]])   \n",
    "else:\n",
    "    #alldocs_df_large_left[tokenize_field] = alldocs_df_large_left[tokenize_field].apply(lambda x: ' '.join([word for word in x.split()[:(token_max-1)]]))\n",
    "    #alldocs_df_large_right[tokenize_field] = alldocs_df_large_right[tokenize_field].apply(lambda x: ' '.join([word for word in x.split()[token_max:(2*token_max)]]))\n",
    "    alldocs_df_large_left[tokenize_field] = alldocs_df_large_left[tokenize_field].apply(lambda x: ' '.join([word for word in x.split()[:(token_max)]]))\n",
    "    alldocs_df_large_right[tokenize_field] = alldocs_df_large_right[tokenize_field].apply(lambda x: ' '.join([word for word in x.split()[(len(x.split())-token_max):len(x.split())]]))\n",
    "\n",
    "alldocs_df_expanded = pd.concat([alldocs_df_ok,alldocs_df_large_right,alldocs_df_large_left])\n",
    "\n",
    "if isTokenized:\n",
    "    alldocs_df_expanded['word_count'] = alldocs_df_expanded[tokenize_field].apply(lambda x: len(x))\n",
    "else:\n",
    "    alldocs_df_expanded['word_count'] = alldocs_df_expanded[tokenize_field].apply(lambda x: len(x.split()))\n",
    "\n",
    "print('All:', sum(alldocs_df_expanded['word_count'] > token_max), \"out of\", len(alldocs_df_expanded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_tokenized</th>\n",
       "      <th>word_tokenized</th>\n",
       "      <th>no_punc_text</th>\n",
       "      <th>no_numerics_text</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>tok_lem_text</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>490646815 | WMC | 31530471 | | 9629480 | 11/23...</td>\n",
       "      <td>[wmc am anemia sign di admiss date report stat...</td>\n",
       "      <td>[wmc, am, anemia, sign, di, admiss, date, repo...</td>\n",
       "      <td>490646815  WMC  31530471   9629480  11232006 1...</td>\n",
       "      <td>WMC         AM  ANEMIA  Signed  DIS  Admissi...</td>\n",
       "      <td>wmc am anemia signed dis admission date report...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>110</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  \\\n",
       "0   1  490646815 | WMC | 31530471 | | 9629480 | 11/23...   \n",
       "\n",
       "                                  sentence_tokenized  \\\n",
       "0  [wmc am anemia sign di admiss date report stat...   \n",
       "\n",
       "                                      word_tokenized  \\\n",
       "0  [wmc, am, anemia, sign, di, admiss, date, repo...   \n",
       "\n",
       "                                        no_punc_text  \\\n",
       "0  490646815  WMC  31530471   9629480  11232006 1...   \n",
       "\n",
       "                                    no_numerics_text  \\\n",
       "0    WMC         AM  ANEMIA  Signed  DIS  Admissi...   \n",
       "\n",
       "                                          lower_text  \\\n",
       "0  wmc am anemia signed dis admission date report...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [wmc, am, anemia, signed, dis, admission, date...   \n",
       "\n",
       "                                        tok_lem_text  sentence_count  \\\n",
       "0  [wmc, am, anemia, signed, dis, admission, date...             110   \n",
       "\n",
       "   word_count  \n",
       "0        1474  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldocs_df[alldocs_df['id']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_tokenized</th>\n",
       "      <th>word_tokenized</th>\n",
       "      <th>no_punc_text</th>\n",
       "      <th>no_numerics_text</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>tok_lem_text</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>490646815 | WMC | 31530471 | | 9629480 | 11/23...</td>\n",
       "      <td>[wmc am anemia sign di admiss date report stat...</td>\n",
       "      <td>[wmc, am, anemia, sign, di, admiss, date, repo...</td>\n",
       "      <td>490646815  WMC  31530471   9629480  11232006 1...</td>\n",
       "      <td>WMC         AM  ANEMIA  Signed  DIS  Admissi...</td>\n",
       "      <td>wmc am anemia signed dis admission date report...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>[with, ejection, fraction, of, to, who, presen...</td>\n",
       "      <td>110</td>\n",
       "      <td>1416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>490646815 | WMC | 31530471 | | 9629480 | 11/23...</td>\n",
       "      <td>[wmc am anemia sign di admiss date report stat...</td>\n",
       "      <td>[wmc, am, anemia, sign, di, admiss, date, repo...</td>\n",
       "      <td>490646815  WMC  31530471   9629480  11232006 1...</td>\n",
       "      <td>WMC         AM  ANEMIA  Signed  DIS  Admissi...</td>\n",
       "      <td>wmc am anemia signed dis admission date report...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>[wmc, am, anemia, signed, dis, admission, date...</td>\n",
       "      <td>110</td>\n",
       "      <td>1416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  \\\n",
       "0   1  490646815 | WMC | 31530471 | | 9629480 | 11/23...   \n",
       "0   1  490646815 | WMC | 31530471 | | 9629480 | 11/23...   \n",
       "\n",
       "                                  sentence_tokenized  \\\n",
       "0  [wmc am anemia sign di admiss date report stat...   \n",
       "0  [wmc am anemia sign di admiss date report stat...   \n",
       "\n",
       "                                      word_tokenized  \\\n",
       "0  [wmc, am, anemia, sign, di, admiss, date, repo...   \n",
       "0  [wmc, am, anemia, sign, di, admiss, date, repo...   \n",
       "\n",
       "                                        no_punc_text  \\\n",
       "0  490646815  WMC  31530471   9629480  11232006 1...   \n",
       "0  490646815  WMC  31530471   9629480  11232006 1...   \n",
       "\n",
       "                                    no_numerics_text  \\\n",
       "0    WMC         AM  ANEMIA  Signed  DIS  Admissi...   \n",
       "0    WMC         AM  ANEMIA  Signed  DIS  Admissi...   \n",
       "\n",
       "                                          lower_text  \\\n",
       "0  wmc am anemia signed dis admission date report...   \n",
       "0  wmc am anemia signed dis admission date report...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [wmc, am, anemia, signed, dis, admission, date...   \n",
       "0  [wmc, am, anemia, signed, dis, admission, date...   \n",
       "\n",
       "                                        tok_lem_text  sentence_count  \\\n",
       "0  [with, ejection, fraction, of, to, who, presen...             110   \n",
       "0  [wmc, am, anemia, signed, dis, admission, date...             110   \n",
       "\n",
       "   word_count  \n",
       "0        1416  \n",
       "0        1416  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldocs_df_expanded[alldocs_df_expanded['id']==1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a one hot vector given a vocabulary and pad it with the padding character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emh', 'am', 'discharge', 'summary', 'signed', 'dis', 'admission', 'date', 'report', 'status', 'signed', 'discharge', 'date', 'principle', 'diagnosis', 'coronary', 'artery', 'disease', 'other', 'diagnosis', 'peripheral', 'vascular', 'disease', 'hypertension', 'allergy', 'no', 'known', 'drug', 'allergy', 'history', 'of', 'present', 'illness', 'the', 'patient', 'is', 'a', 'year', 'old', 'male', 'immigrant', 'from', 'tope', 'ri', 'with', 'a', 'long', 'history', 'of', 'angina', 'he', 'had', 'been', 'followed', 'in', 'the', 'o', 'lake', 'jack', 'for', 'year', 'with', 'strong', 'indication', 'for', 'interventional', 'evaluation', 'of', 'his', 'coronary', 'artery', 'disease', 'the', 'patient', 'had', 'refused', 'and', 'had', 'been', 'being', 'treated', 'medically', 'inspite', 'of', 'the', 'angina', 'pattern', 'recently', 'his', 'angina', 'had', 'worsened', 'and', 'he', 'agreed', 'to', 'undergo', 'more', 'intensive', 'workup', 'he', 'wa', 'referred', 'for', 'elective', 'cardiac', 'catheterization', 'past', 'medical', 'history', 'hospitalization', 'for', 'an', 'episode', 'of', 'chest', 'pain', 'in', 's', 'hypertension', 'and', 'history', 'of', 'peripheral', 'vascular', 'disease', 'with', 'claudication', 'symptom', 'physical', 'examination', 'on', 'physical', 'exam', 'the', 'patient', 'temperature', 'wa', 'heart', 'rate', 'heent', 'head', 'and', 'neck', 'exam', 'unremarkable', 'lung', 'clear', 'anteriorly', 'heart', 'regular', 'rate', 'and', 'rhythm', 'no', 'murmur', 'appreciated', 'abdomen', 'soft', 'nontender', 'extremity', 'no', 'edema', 'had', 'weakly', 'dopplerable', 'pulse', 'of', 'note', 'his', 'physical', 'exam', 'wa', 'performed', 'on', 'his', 'emergent', 'admission', 'to', 'the', 'cardiac', 'care', 'unit', 'after', 'becoming', 'unstable', 'at', 'elective', 'cardiac', 'catheterization', 'laboratory', 'examination', 'his', 'admission', 'laboratory', 'exam', 'wa', 'remarkable', 'for', 'a', 'normal', 'cbc', 'and', 'serum', 'general', 'exam', 'his', 'ekg', 'after', 'cardiac', 'catheterization', 'demonstrated', 'inverted', 't', 'wave', 'in', 'iii', 'f', 'and', 'some', 'st', 'depression', 'in', 'vv', 'hospital', 'course', 'on', 'elective', 'cardiac', 'catheterization', 'the', 'patient', 'wa', 'noted', 'to', 'have', 'a', 'ostial', 'left', 'anterior', 'descending', 'coronary', 'artery', 'lesion', 'he', 'had', 'ekg', 'change', 'symptomatically', 'had', 'chest', 'pain', 'at', 'catheterization', 'he', 'wa', 'referred', 'for', 'emergent', 'coronary', 'artery', 'bypass', 'grafting', 'an', 'intraaortic', 'balloon', 'pump', 'wa', 'placed', 'he', 'wa', 'taken', 'emergently', 'to', 'the', 'operating', 'room', 'where', 'a', 'vessel', 'coronary', 'artery', 'bypass', 'wa', 'performed', 'there', 'were', 'no', 'intraoperative', 'complication', 'postoperatively', 'the', 'patient', 'did', 'remarkably', 'well', 'inspite', 'of', 'his', 'dramatic', 'presentation', 'he', 'had', 'no', 'vascular', 'complication', 'his', 'intraaortic', 'balloon', 'pump', 'wa', 'removed', 'without', 'incident', 'and', 'he', 'had', 'no', 'specific', 'cardiopulmonary', 'complication', 'his', 'only', 'issue', 'at', 'discharge', 'wa', 'urinary', 'retention', 'he', 'failed', 'several', 'voiding', 'trial', 'urology', 'service', 'had', 'consulted', 'and', 'felt', 'this', 'wa', 'likely', 'secondary', 'to', 'benign', 'prostatic', 'hypertrophy', 'disposition', 'he', 'wa', 'discharged', 'home', 'with', 'an', 'indwelling', 'foley', 'catheter', 'with', 'followup', 'arranged', 'at', 'amc', 'urology', 'medication', 'his', 'discharge', 'medication', 'include', 'aspirin', 'a', 'day', 'iron', 'colace', 'mevacor', 'mg', 'q', 'day', 'and', 'tylenol', 'prn', 'he', 'will', 'followup', 'with', 'his', 'cardiologist', 'urology', 'service', 'and', 'with', 'cardiac', 'surgery', 'dictated', 'by', 'gail', 'g', 'fahlsing', 'md', 'ct', 'attending', 'berry', 'o', 'bjornberg', 'md', 'kq', 'zi', 'batch', 'index', 'no', 'wolhxc', 'd', 't', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[7287, 78, 20, 151, 149, 161, 25, 63, 97, 42, 149, 20, 63, 5312, 85, 81, 73, 57, 105, 85, 501, 434, 57, 125, 87, 16, 287, 428, 87, 26, 3, 140, 260, 1, 10, 19, 6, 186, 425, 713, 20861, 51, 28648, 1958, 8, 6, 884, 26, 3, 505, 18, 22, 109, 276, 12, 1, 321, 4955, 4548, 11, 186, 8, 3243, 2249, 11, 2498, 424, 3, 21, 81, 73, 57, 1, 10, 22, 1206, 2, 22, 109, 535, 200, 1600, 12067, 3, 1, 505, 2191, 684, 21, 505, 22, 2026, 2, 18, 2027, 5, 1881, 373, 831, 727, 18, 4, 1653, 11, 1564, 72, 212, 104, 94, 26, 367, 11, 28, 202, 3, 40, 27, 12, 53, 125, 2, 26, 3, 501, 434, 57, 8, 2243, 199, 147, 133, 7, 147, 159, 1, 10, 319, 4, 58, 77, 503, 666, 2, 381, 159, 900, 215, 198, 3260, 58, 143, 77, 2, 129, 16, 266, 1431, 246, 295, 454, 103, 16, 119, 22, 29590, 2184, 195, 3, 348, 21, 147, 159, 4, 436, 7, 21, 2816, 25, 5, 1, 72, 164, 60, 66, 3559, 1061, 17, 1564, 72, 212, 309, 133, 21, 25, 309, 159, 4, 1370, 11, 6, 67, 1317, 2, 1628, 533, 159, 21, 138, 66, 72, 212, 621, 2690, 137, 558, 12, 948, 571, 2, 201, 394, 446, 12, 1443, 45, 59, 7, 1564, 72, 212, 1, 10, 4, 115, 5, 54, 6, 1368, 39, 462, 693, 81, 73, 273, 18, 22, 138, 128, 3386, 22, 40, 27, 17, 212, 18, 4, 1653, 11, 2816, 81, 73, 341, 1238, 28, 2112, 1646, 636, 4, 250, 18, 4, 438, 4336, 5, 1, 820, 172, 523, 6, 901, 81, 73, 341, 4, 436, 86, 33, 16, 2772, 247, 858, 1, 10, 114, 4239, 64, 12067, 3, 21, 5984, 899, 18, 22, 16, 434, 247, 21, 2112, 1646, 636, 4, 834, 117, 2056, 2, 18, 22, 16, 2747, 1948, 247, 21, 441, 541, 17, 20, 4, 672, 2118, 18, 1620, 444, 2219, 1630, 1428, 92, 22, 632, 2, 239, 35, 4, 194, 183, 5, 819, 2662, 1015, 221, 18, 4, 148, 55, 8, 28, 5594, 930, 886, 8, 187, 1905, 17, 3553, 1428, 50, 21, 20, 50, 729, 110, 6, 23, 518, 385, 2612, 9, 84, 23, 2, 592, 74, 18, 49, 187, 8, 21, 603, 1428, 92, 2, 8, 72, 216, 154, 24, 6030, 855, 18885, 36, 233, 118, 6416, 321, 15648, 36, 12212, 10430, 538, 554, 16, 29873, 134, 137, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['emh', 'am', 'discharge', 'summary', 'signed', 'dis', 'admission', 'date', 'report', 'status', 'signed', 'discharge', 'date', 'principle', 'diagnosis', 'coronary', 'artery', 'disease', 'other', 'diagnosis', 'peripheral', 'vascular', 'disease', 'hypertension', 'allergy', 'no', 'known', 'drug', 'allergy', 'history', 'of', 'present', 'illness', 'the', 'patient', 'is', 'a', 'year', 'old', 'male', 'immigrant', 'from', 'tope', 'ri', 'with', 'a', 'long', 'history', 'of', 'angina', 'he', 'had', 'been', 'followed', 'in', 'the', 'o', 'lake', 'jack', 'for', 'year', 'with', 'strong', 'indication', 'for', 'interventional', 'evaluation', 'of', 'his', 'coronary', 'artery', 'disease', 'the', 'patient', 'had', 'refused', 'and', 'had', 'been', 'being', 'treated', 'medically', 'inspite', 'of', 'the', 'angina', 'pattern', 'recently', 'his', 'angina', 'had', 'worsened', 'and', 'he', 'agreed', 'to', 'undergo', 'more', 'intensive', 'workup', 'he', 'wa', 'referred', 'for', 'elective', 'cardiac', 'catheterization', 'past', 'medical', 'history', 'hospitalization', 'for', 'an', 'episode', 'of', 'chest', 'pain', 'in', 's', 'hypertension', 'and', 'history', 'of', 'peripheral', 'vascular', 'disease', 'with', 'claudication', 'symptom', 'physical', 'examination', 'on', 'physical', 'exam', 'the', 'patient', 'temperature', 'wa', 'heart', 'rate', 'heent', 'head', 'and', 'neck', 'exam', 'unremarkable', 'lung', 'clear', 'anteriorly', 'heart', 'regular', 'rate', 'and', 'rhythm', 'no', 'murmur', 'appreciated', 'abdomen', 'soft', 'nontender', 'extremity', 'no', 'edema', 'had', 'weakly', 'dopplerable', 'pulse', 'of', 'note', 'his', 'physical', 'exam', 'wa', 'performed', 'on', 'his', 'emergent', 'admission', 'to', 'the', 'cardiac', 'care', 'unit', 'after', 'becoming', 'unstable', 'at', 'elective', 'cardiac', 'catheterization', 'laboratory', 'examination', 'his', 'admission', 'laboratory', 'exam', 'wa', 'remarkable', 'for', 'a', 'normal', 'cbc', 'and', 'serum', 'general', 'exam', 'his', 'ekg', 'after', 'cardiac', 'catheterization', 'demonstrated', 'inverted', 't', 'wave', 'in', 'iii', 'f', 'and', 'some', 'st', 'depression', 'in', 'vv', 'hospital', 'course', 'on', 'elective', 'cardiac', 'catheterization', 'the', 'patient', 'wa', 'noted', 'to', 'have', 'a', 'ostial', 'left', 'anterior', 'descending', 'coronary', 'artery', 'lesion', 'he', 'had', 'ekg', 'change', 'symptomatically', 'had', 'chest', 'pain', 'at', 'catheterization', 'he', 'wa', 'referred', 'for', 'emergent', 'coronary', 'artery', 'bypass', 'grafting', 'an', 'intraaortic', 'balloon', 'pump', 'wa', 'placed', 'he', 'wa', 'taken', 'emergently', 'to', 'the', 'operating', 'room', 'where', 'a', 'vessel', 'coronary', 'artery', 'bypass', 'wa', 'performed', 'there', 'were', 'no', 'intraoperative', 'complication', 'postoperatively', 'the', 'patient', 'did', 'remarkably', 'well', 'inspite', 'of', 'his', 'dramatic', 'presentation', 'he', 'had', 'no', 'vascular', 'complication', 'his', 'intraaortic', 'balloon', 'pump', 'wa', 'removed', 'without', 'incident', 'and', 'he', 'had', 'no', 'specific', 'cardiopulmonary', 'complication', 'his', 'only', 'issue', 'at', 'discharge', 'wa', 'urinary', 'retention', 'he', 'failed', 'several', 'voiding', 'trial', 'urology', 'service', 'had', 'consulted', 'and', 'felt', 'this', 'wa', 'likely', 'secondary', 'to', 'benign', 'prostatic', 'hypertrophy', 'disposition', 'he', 'wa', 'discharged', 'home', 'with', 'an', 'indwelling', 'foley', 'catheter', 'with', 'followup', 'arranged', 'at', 'amc', 'urology', 'medication', 'his', 'discharge', 'medication', 'include', 'aspirin', 'a', 'day', 'iron', 'colace', 'mevacor', 'mg', 'q', 'day', 'and', 'tylenol', 'prn', 'he', 'will', 'followup', 'with', 'his', 'cardiologist', 'urology', 'service', 'and', 'with', 'cardiac', 'surgery', 'dictated', 'by', 'gail', 'g', 'fahlsing', 'md', 'ct', 'attending', 'berry', 'o', 'bjornberg', 'md', 'kq', 'zi', 'batch', 'index', 'no', 'wolhxc', 'd', 't', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['emh am discharg summari sign di admiss date report statu sign discharg date principl diagnosi coronari arteri diseas', 'other diagnos peripher vascular diseas hypertens', 'allergi no known drug allergi', 'histori of present ill the patient is a year old male immigr from tope ri with a long histori of angina', 'he had been follow in the o lake jack for year with strong indic for intervent evalu of hi coronari arteri diseas', 'the patient had refus and had been be treat medic inspit of the angina pattern', 'recent hi angina had worsen and he agre to undergo more intens workup', 'he wa refer for elect cardiac catheter', 'past medic histori hospit for an episod of chest pain in s hypertens and histori of peripher vascular diseas with claudic symptom', \"physic examin on physic exam the patient' temperatur wa heart rate\", 'heent head and neck exam unremark', 'lung clear anteriorli', 'heart regular rate and rhythm no murmur appreci', 'abdomen soft nontend', 'extrem no edema', 'had weakli doppler pul', 'of note hi physic exam wa perform on hi emerg admiss to the cardiac care unit after becom unstabl at elect cardiac catheter', 'laboratori examin hi admiss laboratori exam wa remark for a normal cbc and serum gener exam', 'hi ekg after cardiac catheter demonstr invert t wave in iii f and some st depress in vv', 'hospit cours on elect cardiac catheter the patient wa note to have a ostial left anterior descend coronari arteri lesion', 'he had ekg chang symptomat had chest pain at catheter', 'he wa refer for emerg coronari arteri bypass graft', 'an intraaort balloon pump wa place', 'he wa taken emerg to the oper room where a vessel coronari arteri bypass wa perform', 'there were no intraop complic', 'postop the patient did remark well inspit of hi dramat present', 'he had no vascular complic', 'hi intraaort balloon pump wa remov without incid and he had no specif cardiopulmonari complic', 'hi onli issu at discharg wa urinari retent', 'he fail sever void trial', 'urolog servic had consult and felt thi wa like secondari to benign prostat hypertrophi', 'disposit he wa discharg home with an indwel foley cathet with followup arrang at amc urolog', 'medic hi discharg medic includ aspirin a day iron colac mevacor mg q day and tylenol prn', 'he will followup with hi cardiologist urolog servic and with cardiac surgeri', 'dictat by gail g fahls md', 'ct attend berri o bjornberg md', 'kq zi batch index no', 'wolhxc d t', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "from typing import Union, Iterable\n",
    "import torchtext, torch, torch.nn.functional as F\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "##Words\n",
    "if isTokenized:\n",
    "    voc = build_vocab_from_iterator(alldocs_df_expanded[tokenize_field].to_list(), specials = ['<pad>'])\n",
    "else:\n",
    "    corpus = alldocs_df_expanded[tokenize_field]\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    tokens = [tokenizer(doc) for doc in corpus]\n",
    "    voc = build_vocab_from_iterator(tokens, specials = ['<pad>'])\n",
    "\n",
    "#need to create one hot encoding but add <pad> to reach max_tokens\n",
    "def encode_and_pad(vocab, input_tokens, token_max):\n",
    "    pad_zeros = token_max - len(input_tokens)\n",
    "    result = vocab.lookup_indices(input_tokens)\n",
    "    if pad_zeros > 0:\n",
    "        result.extend(np.zeros(pad_zeros, dtype=int))\n",
    "    return result\n",
    "\n",
    "#need to create tokens add <pad> to reach max_tokens\n",
    "def token_and_pad(vocab, input_tokens, token_max):\n",
    "    pad_zeros = token_max - len(input_tokens)\n",
    "    result = input_tokens\n",
    "    if pad_zeros > 0:\n",
    "        zeros = []\n",
    "        for i in range(pad_zeros):\n",
    "            zeros.append('<pad>')\n",
    "        result.extend(zeros)\n",
    "    return result\n",
    "\n",
    "#need to create tokens add '\\n' to reach max_sentences\n",
    "def token_and_pad_sentence(input_sentences, sentence_max):\n",
    "    pad_spaces = sentence_max - len(input_sentences)\n",
    "    result = input_sentences\n",
    "    if pad_spaces > 0:\n",
    "        for i in range(pad_spaces):\n",
    "            result.append('\\n')\n",
    "\n",
    "    return result\n",
    "\n",
    "if isTokenized:\n",
    "    alldocs_df_expanded['one_hot'] = alldocs_df_expanded[tokenize_field].apply(lambda x: encode_and_pad(voc, x, token_max))\n",
    "    alldocs_df_expanded['vector_tokenized'] = alldocs_df_expanded[tokenize_field].apply(lambda x: token_and_pad(voc, x, token_max))\n",
    "else:\n",
    "    alldocs_df_expanded['one_hot'] = alldocs_df_expanded[tokenize_field].apply(lambda x: encode_and_pad(voc, x.split(), token_max))\n",
    "    alldocs_df_expanded['vector_tokenized'] = alldocs_df_expanded[tokenize_field].apply(lambda x: token_and_pad(voc, x.split(), token_max))\n",
    "\n",
    "alldocs_df_expanded['sentence_tokenized'] = alldocs_df_expanded['sentence_tokenized'].apply(lambda x: token_and_pad_sentence(x, sentence_max))\n",
    "\n",
    "\n",
    "\n",
    "print(alldocs_df_expanded.iloc[0][tokenize_field])\n",
    "print(alldocs_df_expanded.iloc[0]['one_hot'])\n",
    "print(alldocs_df_expanded.iloc[0]['vector_tokenized'])\n",
    "print(alldocs_df_expanded.iloc[0]['sentence_tokenized'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the test data documents with their associated annotations.  Verify the number of records are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 16325 1118 16325\n",
      "All Expanded: 16325 1274 18584\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.merge(allannot_df,alldocs_df, on='id')\n",
    "all_df_expanded= pd.merge(allannot_df,alldocs_df_expanded,on='id')\n",
    "\n",
    "print(\"All:\", len(allannot_df), len(alldocs_df), len(all_df))\n",
    "print(\"All Expanded:\", len(allannot_df), len(alldocs_df_expanded), len(all_df_expanded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try and validate the numbers are close with the original papers.  You can see the counts are higher for some reason but the percentage occurrence of each disease doesn't change too much so we are good to use the expanded set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_29996\\2001745270.py:1: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only.\n",
      "  df_before = pd.concat([all_df['disease'].value_counts().sort_index(0),all_df[all_df['judgment']==True]['disease'].value_counts().sort_index(0)/all_df['disease'].value_counts().sort_index(0)],axis =1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_29996\\2001745270.py:1: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only.\n",
      "  df_before = pd.concat([all_df['disease'].value_counts().sort_index(0),all_df[all_df['judgment']==True]['disease'].value_counts().sort_index(0)/all_df['disease'].value_counts().sort_index(0)],axis =1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_29996\\2001745270.py:1: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only.\n",
      "  df_before = pd.concat([all_df['disease'].value_counts().sort_index(0),all_df[all_df['judgment']==True]['disease'].value_counts().sort_index(0)/all_df['disease'].value_counts().sort_index(0)],axis =1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_29996\\2001745270.py:2: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only.\n",
      "  df_after = pd.concat([all_df_expanded['disease'].value_counts().sort_index(0),all_df_expanded[all_df_expanded['judgment']==True]['disease'].value_counts().sort_index(0)/all_df_expanded['disease'].value_counts().sort_index(0)],axis =1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_29996\\2001745270.py:2: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only.\n",
      "  df_after = pd.concat([all_df_expanded['disease'].value_counts().sort_index(0),all_df_expanded[all_df_expanded['judgment']==True]['disease'].value_counts().sort_index(0)/all_df_expanded['disease'].value_counts().sort_index(0)],axis =1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_29996\\2001745270.py:2: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only.\n",
      "  df_after = pd.concat([all_df_expanded['disease'].value_counts().sort_index(0),all_df_expanded[all_df_expanded['judgment']==True]['disease'].value_counts().sort_index(0)/all_df_expanded['disease'].value_counts().sort_index(0)],axis =1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count Before</th>\n",
       "      <th>% Before</th>\n",
       "      <th>Count After</th>\n",
       "      <th>% After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asthma</th>\n",
       "      <td>1057</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.143333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAD</th>\n",
       "      <td>1044</td>\n",
       "      <td>0.606322</td>\n",
       "      <td>1192</td>\n",
       "      <td>0.608221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHF</th>\n",
       "      <td>723</td>\n",
       "      <td>0.672199</td>\n",
       "      <td>841</td>\n",
       "      <td>0.693222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Depression</th>\n",
       "      <td>1068</td>\n",
       "      <td>0.220974</td>\n",
       "      <td>1216</td>\n",
       "      <td>0.231086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>1070</td>\n",
       "      <td>0.702804</td>\n",
       "      <td>1221</td>\n",
       "      <td>0.719902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GERD</th>\n",
       "      <td>924</td>\n",
       "      <td>0.239177</td>\n",
       "      <td>1039</td>\n",
       "      <td>0.246391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gallstones</th>\n",
       "      <td>1097</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>1249</td>\n",
       "      <td>0.172938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gout</th>\n",
       "      <td>1102</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>1255</td>\n",
       "      <td>0.136255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypercholesterolemia</th>\n",
       "      <td>961</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>1092</td>\n",
       "      <td>0.553114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>1037</td>\n",
       "      <td>0.812922</td>\n",
       "      <td>1182</td>\n",
       "      <td>0.816413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertriglyceridemia</th>\n",
       "      <td>1079</td>\n",
       "      <td>0.059314</td>\n",
       "      <td>1230</td>\n",
       "      <td>0.060163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OA</th>\n",
       "      <td>1047</td>\n",
       "      <td>0.203438</td>\n",
       "      <td>1192</td>\n",
       "      <td>0.205537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSA</th>\n",
       "      <td>1094</td>\n",
       "      <td>0.147166</td>\n",
       "      <td>1248</td>\n",
       "      <td>0.147436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obesity</th>\n",
       "      <td>1037</td>\n",
       "      <td>0.446480</td>\n",
       "      <td>1179</td>\n",
       "      <td>0.445293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVD</th>\n",
       "      <td>1030</td>\n",
       "      <td>0.157282</td>\n",
       "      <td>1170</td>\n",
       "      <td>0.167521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venous Insufficiency</th>\n",
       "      <td>955</td>\n",
       "      <td>0.078534</td>\n",
       "      <td>1078</td>\n",
       "      <td>0.080705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Count Before  % Before  Count After   % After\n",
       "Asthma                        1057  0.142857         1200  0.143333\n",
       "CAD                           1044  0.606322         1192  0.608221\n",
       "CHF                            723  0.672199          841  0.693222\n",
       "Depression                    1068  0.220974         1216  0.231086\n",
       "Diabetes                      1070  0.702804         1221  0.719902\n",
       "GERD                           924  0.239177         1039  0.246391\n",
       "Gallstones                    1097  0.164084         1249  0.172938\n",
       "Gout                          1102  0.131579         1255  0.136255\n",
       "Hypercholesterolemia           961  0.548387         1092  0.553114\n",
       "Hypertension                  1037  0.812922         1182  0.816413\n",
       "Hypertriglyceridemia          1079  0.059314         1230  0.060163\n",
       "OA                            1047  0.203438         1192  0.205537\n",
       "OSA                           1094  0.147166         1248  0.147436\n",
       "Obesity                       1037  0.446480         1179  0.445293\n",
       "PVD                           1030  0.157282         1170  0.167521\n",
       "Venous Insufficiency           955  0.078534         1078  0.080705"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_before = pd.concat([all_df['disease'].value_counts().sort_index(0),all_df[all_df['judgment']==True]['disease'].value_counts().sort_index(0)/all_df['disease'].value_counts().sort_index(0)],axis =1)\n",
    "df_after = pd.concat([all_df_expanded['disease'].value_counts().sort_index(0),all_df_expanded[all_df_expanded['judgment']==True]['disease'].value_counts().sort_index(0)/all_df_expanded['disease'].value_counts().sort_index(0)],axis =1)\n",
    "df_all = pd.concat([df_before,df_after], axis=1)\n",
    "\n",
    "mapping = {df_all.columns[0]:'new0', df_all.columns[1]: 'new1'}\n",
    "\n",
    "df_all.columns.values[0] = 'Count Before'\n",
    "df_all.columns.values[1] = '% Before'\n",
    "df_all.columns.values[2] = 'Count After'\n",
    "df_all.columns.values[3] = '% After'\n",
    "df_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Note occurrences](images\\note_occurrences.gif)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the final test/train dataset.  We are also saving the vocabulary used and the max number of tokens and sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_pickle(DATA_PATH + '/all_df.pkl') \n",
    "all_df_expanded.to_pickle(DATA_PATH + '/all_df_expanded.pkl') \n",
    "torch.save(voc, DATA_PATH + '/voc.obj')\n",
    "torch.save((token_max, sentence_max), DATA_PATH + '/counts.obj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 318, 351, 3, 5, 153, 140, 51, 403, 8, 6, 1288, 691, 3, 911, 2, 800, 11, 90, 80, 14, 22, 22, 544, 47, 1204, 2, 618, 27, 42, 91, 6, 355, 618, 543, 330, 186, 472, 43, 22, 109, 544, 11, 108, 80, 2, 14, 31, 61, 684, 1187, 6, 59, 3, 1483, 11, 672, 913, 170, 14, 343, 5, 52, 12879, 1093, 1561, 3, 911, 2, 800, 11, 90, 80, 14, 31, 22, 201, 226, 27, 12, 6, 7105, 2315, 970, 15, 47, 867, 14, 4, 333, 5, 54, 6, 179, 3, 469, 51, 1790, 23, 472, 2, 4, 458, 5, 1, 370, 763, 11, 1159, 2, 727, 3, 15, 406, 3617, 50, 2128, 974, 134, 90, 357, 13, 37, 497, 60, 456, 346, 768, 60, 60, 60, 456, 122, 846, 9, 37, 1111, 9, 37, 728, 9, 34, 2050, 9, 34, 232, 9, 34, 518, 760, 9, 13, 34, 2, 697, 34, 104, 94, 26, 152, 986, 57, 1165, 248, 5, 286, 58, 11548, 73, 11323, 868, 2060, 671, 102, 245, 957, 286, 58, 124, 8, 318, 351, 3, 5, 2023, 2237, 57, 8, 420, 327, 543, 2, 977, 327, 769, 163, 258, 26, 3, 430, 265, 1216, 42, 91, 47, 355, 618, 543, 330, 186, 472, 281, 26, 16, 281, 26, 3, 986, 57, 30, 58, 57, 377, 26, 14, 31, 1113, 551, 1327, 8, 55, 164, 12, 3365, 70, 31, 3224, 12, 5, 4378, 8, 15, 1012, 12, 6765, 7439, 12, 14, 423, 736, 384, 2, 1060, 525, 3234, 87, 1308, 2, 1730, 25, 147, 133, 601, 326, 33, 319, 58, 77, 46, 68, 1321, 2, 2879, 7, 172, 332, 1, 10, 19, 6, 6024, 2013, 550, 12, 16, 168, 494, 14, 31, 595, 2287, 524, 19, 1009, 5, 1107, 183, 5, 977, 582, 215, 33, 198, 5, 714, 218, 282, 159, 62, 1063, 8, 58, 77, 12, 1, 53, 32, 4, 1366, 53, 974, 53, 8, 344, 266, 1447, 306, 8, 1371, 6287, 53, 246, 4, 814, 1172, 5, 1266, 12, 1, 547, 4687, 8, 16, 2330, 30, 2605, 103, 62, 522, 1851, 128, 12, 15, 155, 103, 218, 412, 33, 2553, 8, 2288, 1213, 2, 65, 195, 7, 879, 159, 14, 4, 173, 2, 552, 98, 2, 1150, 1033, 629, 580, 2368, 33, 303, 157, 138, 62, 163, 258, 8, 774, 300, 1085, 8, 58, 77, 3, 4646, 2574, 6, 84, 558, 12, 1670, 2, 791, 558, 12, 1, 847, 683, 40, 241, 62, 356, 815, 421, 2, 121, 119, 79, 1367, 1064, 241, 3, 1, 47, 618, 62, 42, 91, 47, 355, 618, 3648, 8, 79, 9934, 12356, 2, 6496, 8690, 433, 39, 618, 1170, 941, 4653, 1492, 7, 62, 2246, 816, 8268, 1522, 8, 1899, 1201, 8344, 2, 2770, 273, 175, 4459, 3675, 8, 1899, 2856, 175, 7684, 32, 4, 1811, 2, 16, 337, 3294, 2, 5523, 8, 1899, 1201, 67, 3605, 70, 16, 881, 743, 30, 326, 3, 317, 743, 2203, 2555, 7, 62, 6, 1455, 1237, 546, 194, 12, 1, 5119, 430, 265, 7511, 2, 7943, 12, 1, 643, 430, 265, 1114, 7, 621, 6452, 4333, 330, 751, 3477, 4781, 1522, 2, 444, 430, 4781, 1522, 12, 1, 7681, 184, 47, 7107, 623, 7830, 7, 24, 52, 6667, 11754, 45, 59, 24, 440, 261, 793, 12, 1, 370, 763, 1, 10, 601, 326, 33, 319, 58, 77, 1321, 46, 68, 8, 2879, 7, 172, 332, 14, 4, 333, 5, 54, 1572, 1005, 222, 600, 2, 261, 4, 632, 14, 4, 130, 7, 120, 529, 9, 37, 2, 4, 82, 818, 708, 9, 366, 2, 108, 60, 3, 2054, 2, 14, 4, 1613, 191, 60, 3, 1228, 730, 46, 254, 8, 75, 9, 120, 11, 785, 2900, 3, 348, 1, 10, 22, 6, 1114, 12, 4, 7, 43, 62, 743, 1078, 546, 8, 1021, 449, 8, 630, 1686, 28, 1492, 7, 62, 6, 2246, 816, 8268, 1522, 4227, 11967, 175, 4459, 3675, 4227, 175, 7684, 1811, 16, 337, 3294, 5523, 4227, 67, 3605, 70, 16, 881, 743, 30, 326, 3, 317, 743, 2203, 2555, 7, 62, 1455, 1237, 546, 194, 12, 1, 5119, 430, 265, 7511, 2, 7943, 12, 1, 643, 430, 265, 43, 33, 1373, 1, 194, 1244, 3, 743, 1114, 4, 436, 7, 5, 5757, 11, 10570, 11, 43, 902, 467, 29, 353, 70, 621, 441, 6, 6452, 4333, 2, 330, 751, 3477, 4781, 1522, 2, 444, 430, 4781, 1522, 12, 1, 7681, 1, 10, 4, 130, 7, 3073, 70, 22, 6, 641, 179, 836, 51, 5, 7, 11, 43, 14, 325, 1305, 108, 60, 3, 46, 1334, 8, 75, 1, 10, 179, 255, 79, 17, 330, 5, 2, 14, 49, 29, 562, 7, 837, 7, 1524, 90, 80, 66, 15, 1043, 1575, 216, 83, 1, 10, 31, 152, 986, 57, 2, 19, 535, 1373, 11, 6, 353, 739, 12, 1, 1354, 14, 4, 89, 7, 15, 2128, 974, 134, 697, 2, 518, 2171, 2, 14, 4, 130, 7, 3073, 507, 2008, 2, 4, 82, 3124, 9, 1229, 11, 234, 2704, 352, 623, 5641, 157, 4, 436, 7, 2, 6, 47, 7107, 623, 7830, 4, 436, 7, 24, 52, 12244, 1, 10, 22, 225, 47, 1084, 7215, 1521, 2, 800, 2200, 8, 2184, 1261, 195, 51, 5356, 1160, 8529, 43, 4, 356, 24, 1, 48, 3, 20, 14, 49, 100, 69, 8, 52, 10965, 6, 28, 220, 1, 10, 123, 4, 7, 25, 356, 5, 24, 43, 4, 1, 23, 3, 15, 216, 2, 171, 581, 5, 7, 14, 4, 82, 120, 75, 1360, 6, 14, 22, 196, 3, 459, 717, 8, 204, 11422, 203, 1125, 131, 15, 367, 2, 123, 356, 5, 24, 1, 23, 3, 20, 282, 636, 1, 10, 318, 351, 19, 5, 2, 14, 4, 82, 9, 3, 120, 75, 11, 785, 60, 3, 1228, 730, 46, 254, 14, 339, 1334, 8, 9, 13, 34, 8, 120, 1360, 3, 9, 6, 495, 11, 459, 717, 6, 4951, 24, 28, 620, 12, 15, 203, 2371, 50, 33, 2190, 450, 11, 15, 261, 793, 2, 530, 33, 562, 7, 8, 344, 46, 68, 2139, 12, 1, 53, 5, 53, 129, 1, 10, 31, 163, 258, 8, 774, 300, 1085, 8, 58, 77, 6, 145, 6, 1, 280, 53, 1590, 15, 58, 77, 1041, 143, 2, 4, 466, 5, 29, 3158, 7303, 129, 14, 4, 1008, 306, 15, 367, 14, 4, 1276, 8, 15, 603, 52, 7341, 153, 49, 1090, 6, 758, 6, 28, 220, 640, 14, 19, 5181, 8, 1010, 3, 11, 15, 102, 14, 339, 1471, 497, 8, 1465, 1229, 2, 331, 267, 211, 1688, 2, 143, 99, 331, 267, 181, 211, 1137, 1909, 33, 234, 5, 53, 996, 131, 35, 25, 70, 356, 5, 1, 53, 223, 489, 15, 99, 135, 2020, 1, 10, 19, 42, 91, 47, 355, 618, 543, 330, 186, 472, 2, 1223, 3, 47, 618, 27, 223, 25, 28, 241, 62, 79, 3648, 2, 1, 27, 4, 356, 24, 1, 520, 3, 14, 49, 100, 8, 12945, 52, 5116, 12202, 247, 47, 1084, 800, 1521, 2, 7215, 42, 91, 1043, 1575, 216, 1302, 183, 5, 5356, 30, 8529, 1591, 356, 24, 1, 48, 3, 20, 2481, 52, 5201, 12180, 51, 434, 216, 52, 4456, 12548, 51, 3415, 147, 133, 7, 20, 79, 601, 326, 215, 8, 1112, 637, 344, 266, 1447, 306, 974, 6, 1371, 53, 246, 819, 155, 103, 8, 152, 522, 1851, 128, 47, 280, 103, 1043, 1575, 8, 3461, 271, 47, 1261, 195, 8, 898, 1084, 2906, 2, 963, 12, 1084, 7360, 3, 1, 47, 1084, 20, 50, 857, 9, 34, 2128, 974, 134, 90, 448, 13, 37, 3073, 507, 859, 2008, 602, 9, 859, 34, 237, 7, 1524, 5, 29, 439, 211, 10, 126, 19, 586, 7, 88, 529, 9, 13, 37, 1290, 760, 9, 13, 37, 75, 9, 13, 34, 99, 1465, 60, 859, 413, 470, 99, 497, 60, 859, 346, 846, 9, 13, 37, 3124, 9, 13, 1229, 697, 90, 448, 34, 2050, 9, 13, 34, 2, 88, 9, 13, 346, 237, 7, 1524, 221, 5, 55, 8, 92, 187, 174, 1, 10, 49, 100, 69, 8, 52, 5903, 156, 13881, 12, 90, 5, 108, 80, 8, 52, 13457, 51, 434, 216, 7, 17, 78, 8, 52, 6909, 27157, 51, 25016, 7, 17, 78, 2, 52, 8472, 23935, 7, 17, 78, 178, 42, 1, 10, 19, 231, 178, 2, 15, 1808, 2428, 19, 15, 1012, 6278, 22507, 299, 164, 480, 5345, 22676, 36, 633, 619, 1856, 817, 154, 24, 15419, 5615, 118, 9505, 8472, 7473, 465, 340, 134, 137]\n",
      "torch.Size([1416, 300])\n",
      "['with', 'ejection', 'fraction', 'of', 'to', 'who', 'present', 'from', 'clinic', 'with', 'a', 'chief', 'complaint', 'of', 'fatigue', 'and', 'weakness', 'for', 'one', 'week', 'she', 'had', 'had', 'worsening', 'right', 'groin', 'and', 'hip', 'pain', 'status', 'post', 'a', 'total', 'hip', 'replacement', 'approximately', 'year', 'ago', 'which', 'had', 'been', 'worsening', 'for', 'two', 'week', 'and', 'she', 'ha', 'also', 'recently', 'completed', 'a', 'course', 'of', 'levaquin', 'for', 'urinary', 'tract', 'infection', 'she', 'presented', 'to', 'dr', 'parrent', 'office', 'complaining', 'of', 'fatigue', 'and', 'weakness', 'for', 'one', 'week', 'she', 'ha', 'had', 'some', 'abdominal', 'pain', 'in', 'a', 'bandlike', 'distribution', 'around', 'her', 'right', 'side', 'she', 'wa', 'found', 'to', 'have', 'a', 'hematocrit', 'of', 'down', 'from', 'eight', 'day', 'ago', 'and', 'wa', 'sent', 'to', 'the', 'emergency', 'department', 'for', 'transfusion', 'and', 'workup', 'of', 'her', 'anemia', 'preadmission', 'medication', 'caltrate', 'plus', 'd', 'one', 'tab', 'po', 'bid', 'lantus', 'unit', 'sc', 'qpm', 'novolog', 'unit', 'unit', 'unit', 'sc', 'tid', 'imdur', 'mg', 'bid', 'amlodipine', 'mg', 'bid', 'furosemide', 'mg', 'daily', 'valsartan', 'mg', 'daily', 'warfarin', 'mg', 'daily', 'iron', 'sulfate', 'mg', 'po', 'daily', 'and', 'multivitamin', 'daily', 'past', 'medical', 'history', 'chronic', 'kidney', 'disease', 'presumed', 'due', 'to', 'congestive', 'heart', 'failurediuresisrenal', 'artery', 'diseaseearly', 'diabetic', 'nephropathy', 'type', 'diabetes', 'previous', 'stroke', 'congestive', 'heart', 'failure', 'with', 'ejection', 'fraction', 'of', 'to', 'rheumatic', 'valvular', 'disease', 'with', 'mitral', 'valve', 'replacement', 'and', 'tricuspid', 'valve', 'repair', 'atrial', 'fibrillation', 'history', 'of', 'small', 'bowel', 'obstruction', 'status', 'post', 'right', 'total', 'hip', 'replacement', 'approximately', 'year', 'ago', 'family', 'history', 'no', 'family', 'history', 'of', 'kidney', 'disease', 'or', 'heart', 'disease', 'social', 'history', 'she', 'ha', 'child', 'life', 'alone', 'with', 'home', 'care', 'in', 'me', 'but', 'ha', 'moved', 'in', 'to', 'live', 'with', 'her', 'daughter', 'in', 'news', 'irv', 'in', 'she', 'denies', 'tobacco', 'use', 'and', 'drink', 'alcohol', 'rarely', 'allergy', 'codeine', 'and', 'benadryl', 'admission', 'physical', 'examination', 'vital', 'sign', 'were', 'temperature', 'heart', 'rate', 'blood', 'pressure', 'respiration', 'and', 'sao', 'on', 'room', 'air', 'the', 'patient', 'is', 'a', 'frail', 'elderly', 'woman', 'in', 'no', 'acute', 'distress', 'she', 'ha', 'poor', 'dentition', 'jvp', 'is', 'difficult', 'to', 'ass', 'secondary', 'to', 'tricuspid', 'regurgitation', 'lung', 'were', 'clear', 'to', 'auscultation', 'bilaterally', 'cardiovascular', 'exam', 'showed', 'bradycardia', 'with', 'heart', 'rate', 'in', 'the', 's', 'that', 'wa', 'irregular', 's', 'plus', 's', 'with', 'systolic', 'murmur', 'heard', 'throughout', 'with', 'mechanical', 'sounding', 's', 'abdomen', 'wa', 'mildly', 'tender', 'to', 'palpation', 'in', 'the', 'mid', 'epigastrium', 'with', 'no', 'rebound', 'or', 'guarding', 'extremity', 'showed', 'venous', 'stasis', 'change', 'in', 'her', 'lower', 'extremity', 'bilaterally', 'foot', 'were', 'cool', 'with', 'diminished', 'dp', 'and', 'pt', 'pulse', 'on', 'neurological', 'exam', 'she', 'wa', 'alert', 'and', 'oriented', 'x', 'and', 'cranial', 'nerve', 'ii', 'through', 'xii', 'were', 'intact', 'study', 'ekg', 'showed', 'atrial', 'fibrillation', 'with', 'slow', 'ventricular', 'response', 'with', 'heart', 'rate', 'of', 'widened', 'qrs', 'a', 'q', 'wave', 'in', 'avl', 'and', 'u', 'wave', 'in', 'the', 'lateral', 'lead', 'chest', 'xray', 'showed', 'improved', 'pleural', 'effusion', 'and', 'pulmonary', 'edema', 'stable', 'marked', 'cardiomegaly', 'xray', 'of', 'the', 'right', 'hip', 'showed', 'status', 'post', 'right', 'total', 'hip', 'arthroplasty', 'with', 'stable', 'periprosthetic', 'lucency', 'and', 'cortical', 'remodeling', 'severe', 'left', 'hip', 'osteoarthritis', 'diffuse', 'atherosclerosis', 'egd', 'on', 'showed', 'hiatal', 'hernia', 'fundic', 'polyp', 'with', 'pathology', 'showing', 'hypoplastic', 'and', 'inflammatory', 'lesion', 'mild', 'antral', 'erosion', 'with', 'pathology', 'demonstrating', 'mild', 'regeneration', 'that', 'wa', 'nonspecific', 'and', 'no', 'h', 'pylorus', 'and', 'duodenitis', 'with', 'pathology', 'showing', 'normal', 'mucosa', 'but', 'no', 'active', 'bleeding', 'or', 'sign', 'of', 'recent', 'bleeding', 'capsule', 'endoscopy', 'on', 'showed', 'a', 'healing', 'gastric', 'ulcer', 'likely', 'in', 'the', 'antrum', 'small', 'bowel', 'lymphangiectasia', 'and', 'angioectasia', 'in', 'the', 'distal', 'small', 'bowel', 'colonoscopy', 'on', 'demonstrated', 'cecal', 'diverticulum', 'approximately', 'mm', 'ascending', 'sessile', 'polyp', 'and', 'several', 'small', 'sessile', 'polyp', 'in', 'the', 'rectosigmoid', 'procedure', 'right', 'basilic', 'vein', 'transposition', 'on', 'by', 'dr', 'jacinto', 'goonez', 'hospital', 'course', 'by', 'problem', 'gi', 'bleed', 'in', 'the', 'emergency', 'department', 'the', 'patient', 'vital', 'sign', 'were', 'temperature', 'heart', 'rate', 'respiration', 'blood', 'pressure', 'with', 'sao', 'on', 'room', 'air', 'she', 'wa', 'found', 'to', 'have', 'black', 'guaiac', 'positive', 'stool', 'and', 'gi', 'wa', 'consulted', 'she', 'wa', 'started', 'on', 'iv', 'nexium', 'mg', 'bid', 'and', 'wa', 'given', 'vitamin', 'k', 'mg', 'subcutaneously', 'and', 'two', 'unit', 'of', 'ffp', 'and', 'she', 'wa', 'transfused', 'three', 'unit', 'of', 'packed', 'red', 'blood', 'cell', 'with', 'lasix', 'mg', 'iv', 'for', 'each', 'bag', 'of', 'note', 'the', 'patient', 'had', 'a', 'colonoscopy', 'in', 'wa', 'on', 'which', 'showed', 'bleeding', 'rectal', 'ulcer', 'with', 'biopsy', 'consistent', 'with', 'ischemic', 'colitis', 'an', 'egd', 'on', 'showed', 'a', 'hiatal', 'hernia', 'fundic', 'polyp', 'path', 'hypoplasticinflammatory', 'mild', 'antral', 'erosion', 'path', 'mild', 'regeneration', 'nonspecific', 'no', 'h', 'pylorus', 'duodenitis', 'path', 'normal', 'mucosa', 'but', 'no', 'active', 'bleeding', 'or', 'sign', 'of', 'recent', 'bleeding', 'capsule', 'endoscopy', 'on', 'showed', 'healing', 'gastric', 'ulcer', 'likely', 'in', 'the', 'antrum', 'small', 'bowel', 'lymphangiectasia', 'and', 'angioectasia', 'in', 'the', 'distal', 'small', 'bowel', 'which', 'were', 'considered', 'the', 'likely', 'source', 'of', 'bleeding', 'colonoscopy', 'wa', 'performed', 'on', 'to', 'search', 'for', 'angioectasias', 'for', 'which', 'intervention', 'would', 'be', 'possible', 'but', 'demonstrated', 'only', 'a', 'cecal', 'diverticulum', 'and', 'approximately', 'mm', 'ascending', 'sessile', 'polyp', 'and', 'several', 'small', 'sessile', 'polyp', 'in', 'the', 'rectosigmoid', 'the', 'patient', 'wa', 'started', 'on', 'aranesp', 'but', 'had', 'a', 'point', 'hematocrit', 'drop', 'from', 'to', 'on', 'for', 'which', 'she', 'required', 'another', 'two', 'unit', 'of', 'blood', 'along', 'with', 'lasix', 'the', 'patient', 'hematocrit', 'remained', 'stable', 'at', 'approximately', 'to', 'and', 'she', 'will', 'be', 'restarted', 'on', 'anticoagulation', 'on', 'thursday', 'one', 'week', 'after', 'her', 'av', 'fistula', 'surgery', 'renal', 'the', 'patient', 'ha', 'chronic', 'kidney', 'disease', 'and', 'is', 'being', 'considered', 'for', 'a', 'possible', 'hemodialysis', 'in', 'the', 'future', 'she', 'wa', 'continued', 'on', 'her', 'caltrate', 'plus', 'd', 'multivitamin', 'and', 'iron', 'supplementation', 'and', 'she', 'wa', 'started', 'on', 'aranesp', 'mcg', 'weekly', 'and', 'wa', 'given', 'sevelamer', 'mg', 'qac', 'for', 'elevated', 'phosphate', 'level', 'vein', 'mapping', 'study', 'wa', 'performed', 'on', 'and', 'a', 'right', 'basilic', 'vein', 'transposition', 'wa', 'performed', 'on', 'by', 'dr', 'landrie', 'the', 'patient', 'had', 'postoperative', 'right', 'hand', 'coolness', 'numbness', 'and', 'weakness', 'always', 'with', 'dopplerable', 'radial', 'pulse', 'from', 'steal', 'versus', 'neurapraxia', 'which', 'wa', 'improved', 'by', 'the', 'time', 'of', 'discharge', 'she', 'will', 'follow', 'up', 'with', 'dr', 'chanthasene', 'a', 'an', 'outpatient', 'the', 'patient', 'creatinine', 'wa', 'on', 'admission', 'improved', 'to', 'by', 'which', 'wa', 'the', 'day', 'of', 'her', 'surgery', 'and', 'increased', 'again', 'to', 'on', 'she', 'wa', 'given', 'iv', 'lasix', 'bolus', 'a', 'she', 'had', 'evidence', 'of', 'volume', 'overload', 'with', 'over', 'eightpound', 'weight', 'gain', 'during', 'her', 'hospitalization', 'and', 'creatinine', 'improved', 'to', 'by', 'the', 'day', 'of', 'discharge', 'cardiovascular', 'pump', 'the', 'patient', 'ejection', 'fraction', 'is', 'to', 'and', 'she', 'wa', 'given', 'mg', 'of', 'iv', 'lasix', 'for', 'each', 'unit', 'of', 'packed', 'red', 'blood', 'cell', 'she', 'received', 'along', 'with', 'mg', 'po', 'daily', 'with', 'iv', 'bolus', 'of', 'mg', 'a', 'needed', 'for', 'volume', 'overload', 'a', 'judged', 'by', 'an', 'increase', 'in', 'her', 'weight', 'antihypertensive', 'medication', 'were', 'originally', 'held', 'for', 'her', 'gi', 'bleed', 'and', 'they', 'were', 'restarted', 'on', 'with', 'systolic', 'blood', 'pressure', 'remaining', 'in', 'the', 's', 'to', 's', 'rhythm', 'the', 'patient', 'ha', 'atrial', 'fibrillation', 'with', 'slow', 'ventricular', 'response', 'with', 'heart', 'rate', 'a', 'low', 'a', 'the', 'upper', 's', 'occasionally', 'her', 'heart', 'rate', 'appeared', 'regular', 'and', 'wa', 'thought', 'to', 'be', 'junctional', 'escape', 'rhythm', 'she', 'wa', 'asymptomatic', 'throughout', 'her', 'hospitalization', 'she', 'wa', 'discussed', 'with', 'her', 'cardiologist', 'dr', 'fritz', 'who', 'will', 'consider', 'a', 'pacemaker', 'a', 'an', 'outpatient', 'endocrine', 'she', 'is', 'euthyroid', 'with', 'tsh', 'of', 'for', 'her', 'diabetes', 'she', 'received', 'nightly', 'lantus', 'with', 'aspart', 'qac', 'and', 'sliding', 'scale', 'when', 'eating', 'and', 'regular', 'insulin', 'sliding', 'scale', 'qh', 'when', 'npo', 'fingersticks', 'were', 'elevated', 'to', 's', 'early', 'during', 'this', 'admission', 'but', 'improved', 'to', 'the', 's', 'upon', 'increasing', 'her', 'insulin', 'dose', 'musculoskeletal', 'the', 'patient', 'is', 'status', 'post', 'right', 'total', 'hip', 'replacement', 'approximately', 'year', 'ago', 'and', 'complained', 'of', 'right', 'hip', 'pain', 'upon', 'admission', 'an', 'xray', 'showed', 'stable', 'arthroplasty', 'and', 'the', 'pain', 'wa', 'improved', 'by', 'the', 'morning', 'of', 'she', 'will', 'follow', 'with', 'physiatrist', 'dr', 'allan', 'kofoed', 'complication', 'right', 'hand', 'weakness', 'numbness', 'and', 'coolness', 'status', 'post', 'av', 'fistula', 'surgery', 'possibly', 'secondary', 'to', 'steal', 'or', 'neurapraxia', 'significantly', 'improved', 'by', 'the', 'time', 'of', 'discharge', 'consultant', 'dr', 'garfield', 'kiehne', 'from', 'vascular', 'surgery', 'dr', 'ambrose', 'moldrem', 'from', 'gastroenterology', 'physical', 'examination', 'on', 'discharge', 'stable', 'vital', 'sign', 'lung', 'with', 'bibasilar', 'crackle', 'systolic', 'murmur', 'heard', 'throughout', 'plus', 'a', 'mechanical', 's', 'abdomen', 'benign', 'lower', 'extremity', 'with', 'chronic', 'venous', 'stasis', 'change', 'right', 'upper', 'extremity', 'av', 'fistula', 'with', 'thrill', 'decreased', 'right', 'radial', 'pulse', 'with', 'warm', 'hand', 'distally', 'and', 'strength', 'in', 'hand', 'grip', 'of', 'the', 'right', 'hand', 'discharge', 'medication', 'norvasc', 'mg', 'daily', 'caltrate', 'plus', 'd', 'one', 'tablet', 'po', 'bid', 'aranesp', 'mcg', 'subcu', 'weekly', 'lovenox', 'mg', 'subcu', 'daily', 'starting', 'on', 'thursday', 'to', 'be', 'discontinued', 'when', 'patient', 'inr', 'is', 'therapeutic', 'on', 'coumadin', 'nexium', 'mg', 'po', 'bid', 'ferrous', 'sulfate', 'mg', 'po', 'bid', 'lasix', 'mg', 'po', 'daily', 'insulin', 'aspart', 'unit', 'subcu', 'every', 'meal', 'insulin', 'lantus', 'unit', 'subcu', 'qpm', 'imdur', 'mg', 'po', 'bid', 'sevelamer', 'mg', 'po', 'qac', 'multivitamin', 'one', 'tablet', 'daily', 'valsartan', 'mg', 'po', 'daily', 'and', 'coumadin', 'mg', 'po', 'qpm', 'starting', 'on', 'thursday', 'disposition', 'to', 'home', 'with', 'service', 'followup', 'appointment', 'the', 'patient', 'will', 'follow', 'up', 'with', 'dr', 'brendan', 'b', 'tordsen', 'in', 'one', 'to', 'two', 'week', 'with', 'dr', 'schaetzle', 'from', 'vascular', 'surgery', 'on', 'at', 'am', 'with', 'dr', 'salvatore', 'sherrod', 'from', 'physiatry', 'on', 'at', 'am', 'and', 'dr', 'margarito', 'nolting', 'on', 'at', 'am', 'code', 'status', 'the', 'patient', 'is', 'full', 'code', 'and', 'her', 'healthcare', 'proxy', 'is', 'her', 'daughter', 'shane', 'lutao', 'primary', 'care', 'physician', 'rufus', 'mannheimer', 'md', 'escription', 'document', 'cssten', 'tel', 'dictated', 'by', 'beier', 'julio', 'attending', 'hambric', 'margarito', 'kurt', 'dictation', 'id', 'd', 't']\n",
      "torch.Size([1416, 300])\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import vocab\n",
    "\n",
    "\n",
    "vec = torchtext.vocab.GloVe(name='6B', dim=300)\n",
    "\n",
    "one_hot_test = all_df_expanded.iloc[0]['one_hot']\n",
    "vector_tokenized_test = all_df_expanded.iloc[0]['vector_tokenized']\n",
    "\n",
    "print(one_hot_test)\n",
    "ret = vec.get_vecs_by_tokens(voc.lookup_tokens(one_hot_test))\n",
    "print(ret.shape)\n",
    "#print(ret[0])\n",
    "print(vector_tokenized_test)\n",
    "ret = vec.get_vecs_by_tokens(vector_tokenized_test)\n",
    "print(ret.shape)\n",
    "#print(ret[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the FastText embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 318, 351, 3, 5, 153, 140, 51, 403, 8, 6, 1288, 691, 3, 911, 2, 800, 11, 90, 80, 14, 22, 22, 544, 47, 1204, 2, 618, 27, 42, 91, 6, 355, 618, 543, 330, 186, 472, 43, 22, 109, 544, 11, 108, 80, 2, 14, 31, 61, 684, 1187, 6, 59, 3, 1483, 11, 672, 913, 170, 14, 343, 5, 52, 12879, 1093, 1561, 3, 911, 2, 800, 11, 90, 80, 14, 31, 22, 201, 226, 27, 12, 6, 7105, 2315, 970, 15, 47, 867, 14, 4, 333, 5, 54, 6, 179, 3, 469, 51, 1790, 23, 472, 2, 4, 458, 5, 1, 370, 763, 11, 1159, 2, 727, 3, 15, 406, 3617, 50, 2128, 974, 134, 90, 357, 13, 37, 497, 60, 456, 346, 768, 60, 60, 60, 456, 122, 846, 9, 37, 1111, 9, 37, 728, 9, 34, 2050, 9, 34, 232, 9, 34, 518, 760, 9, 13, 34, 2, 697, 34, 104, 94, 26, 152, 986, 57, 1165, 248, 5, 286, 58, 11548, 73, 11323, 868, 2060, 671, 102, 245, 957, 286, 58, 124, 8, 318, 351, 3, 5, 2023, 2237, 57, 8, 420, 327, 543, 2, 977, 327, 769, 163, 258, 26, 3, 430, 265, 1216, 42, 91, 47, 355, 618, 543, 330, 186, 472, 281, 26, 16, 281, 26, 3, 986, 57, 30, 58, 57, 377, 26, 14, 31, 1113, 551, 1327, 8, 55, 164, 12, 3365, 70, 31, 3224, 12, 5, 4378, 8, 15, 1012, 12, 6765, 7439, 12, 14, 423, 736, 384, 2, 1060, 525, 3234, 87, 1308, 2, 1730, 25, 147, 133, 601, 326, 33, 319, 58, 77, 46, 68, 1321, 2, 2879, 7, 172, 332, 1, 10, 19, 6, 6024, 2013, 550, 12, 16, 168, 494, 14, 31, 595, 2287, 524, 19, 1009, 5, 1107, 183, 5, 977, 582, 215, 33, 198, 5, 714, 218, 282, 159, 62, 1063, 8, 58, 77, 12, 1, 53, 32, 4, 1366, 53, 974, 53, 8, 344, 266, 1447, 306, 8, 1371, 6287, 53, 246, 4, 814, 1172, 5, 1266, 12, 1, 547, 4687, 8, 16, 2330, 30, 2605, 103, 62, 522, 1851, 128, 12, 15, 155, 103, 218, 412, 33, 2553, 8, 2288, 1213, 2, 65, 195, 7, 879, 159, 14, 4, 173, 2, 552, 98, 2, 1150, 1033, 629, 580, 2368, 33, 303, 157, 138, 62, 163, 258, 8, 774, 300, 1085, 8, 58, 77, 3, 4646, 2574, 6, 84, 558, 12, 1670, 2, 791, 558, 12, 1, 847, 683, 40, 241, 62, 356, 815, 421, 2, 121, 119, 79, 1367, 1064, 241, 3, 1, 47, 618, 62, 42, 91, 47, 355, 618, 3648, 8, 79, 9934, 12356, 2, 6496, 8690, 433, 39, 618, 1170, 941, 4653, 1492, 7, 62, 2246, 816, 8268, 1522, 8, 1899, 1201, 8344, 2, 2770, 273, 175, 4459, 3675, 8, 1899, 2856, 175, 7684, 32, 4, 1811, 2, 16, 337, 3294, 2, 5523, 8, 1899, 1201, 67, 3605, 70, 16, 881, 743, 30, 326, 3, 317, 743, 2203, 2555, 7, 62, 6, 1455, 1237, 546, 194, 12, 1, 5119, 430, 265, 7511, 2, 7943, 12, 1, 643, 430, 265, 1114, 7, 621, 6452, 4333, 330, 751, 3477, 4781, 1522, 2, 444, 430, 4781, 1522, 12, 1, 7681, 184, 47, 7107, 623, 7830, 7, 24, 52, 6667, 11754, 45, 59, 24, 440, 261, 793, 12, 1, 370, 763, 1, 10, 601, 326, 33, 319, 58, 77, 1321, 46, 68, 8, 2879, 7, 172, 332, 14, 4, 333, 5, 54, 1572, 1005, 222, 600, 2, 261, 4, 632, 14, 4, 130, 7, 120, 529, 9, 37, 2, 4, 82, 818, 708, 9, 366, 2, 108, 60, 3, 2054, 2, 14, 4, 1613, 191, 60, 3, 1228, 730, 46, 254, 8, 75, 9, 120, 11, 785, 2900, 3, 348, 1, 10, 22, 6, 1114, 12, 4, 7, 43, 62, 743, 1078, 546, 8, 1021, 449, 8, 630, 1686, 28, 1492, 7, 62, 6, 2246, 816, 8268, 1522, 4227, 11967, 175, 4459, 3675, 4227, 175, 7684, 1811, 16, 337, 3294, 5523, 4227, 67, 3605, 70, 16, 881, 743, 30, 326, 3, 317, 743, 2203, 2555, 7, 62, 1455, 1237, 546, 194, 12, 1, 5119, 430, 265, 7511, 2, 7943, 12, 1, 643, 430, 265, 43, 33, 1373, 1, 194, 1244, 3, 743, 1114, 4, 436, 7, 5, 5757, 11, 10570, 11, 43, 902, 467, 29, 353, 70, 621, 441, 6, 6452, 4333, 2, 330, 751, 3477, 4781, 1522, 2, 444, 430, 4781, 1522, 12, 1, 7681, 1, 10, 4, 130, 7, 3073, 70, 22, 6, 641, 179, 836, 51, 5, 7, 11, 43, 14, 325, 1305, 108, 60, 3, 46, 1334, 8, 75, 1, 10, 179, 255, 79, 17, 330, 5, 2, 14, 49, 29, 562, 7, 837, 7, 1524, 90, 80, 66, 15, 1043, 1575, 216, 83, 1, 10, 31, 152, 986, 57, 2, 19, 535, 1373, 11, 6, 353, 739, 12, 1, 1354, 14, 4, 89, 7, 15, 2128, 974, 134, 697, 2, 518, 2171, 2, 14, 4, 130, 7, 3073, 507, 2008, 2, 4, 82, 3124, 9, 1229, 11, 234, 2704, 352, 623, 5641, 157, 4, 436, 7, 2, 6, 47, 7107, 623, 7830, 4, 436, 7, 24, 52, 12244, 1, 10, 22, 225, 47, 1084, 7215, 1521, 2, 800, 2200, 8, 2184, 1261, 195, 51, 5356, 1160, 8529, 43, 4, 356, 24, 1, 48, 3, 20, 14, 49, 100, 69, 8, 52, 10965, 6, 28, 220, 1, 10, 123, 4, 7, 25, 356, 5, 24, 43, 4, 1, 23, 3, 15, 216, 2, 171, 581, 5, 7, 14, 4, 82, 120, 75, 1360, 6, 14, 22, 196, 3, 459, 717, 8, 204, 11422, 203, 1125, 131, 15, 367, 2, 123, 356, 5, 24, 1, 23, 3, 20, 282, 636, 1, 10, 318, 351, 19, 5, 2, 14, 4, 82, 9, 3, 120, 75, 11, 785, 60, 3, 1228, 730, 46, 254, 14, 339, 1334, 8, 9, 13, 34, 8, 120, 1360, 3, 9, 6, 495, 11, 459, 717, 6, 4951, 24, 28, 620, 12, 15, 203, 2371, 50, 33, 2190, 450, 11, 15, 261, 793, 2, 530, 33, 562, 7, 8, 344, 46, 68, 2139, 12, 1, 53, 5, 53, 129, 1, 10, 31, 163, 258, 8, 774, 300, 1085, 8, 58, 77, 6, 145, 6, 1, 280, 53, 1590, 15, 58, 77, 1041, 143, 2, 4, 466, 5, 29, 3158, 7303, 129, 14, 4, 1008, 306, 15, 367, 14, 4, 1276, 8, 15, 603, 52, 7341, 153, 49, 1090, 6, 758, 6, 28, 220, 640, 14, 19, 5181, 8, 1010, 3, 11, 15, 102, 14, 339, 1471, 497, 8, 1465, 1229, 2, 331, 267, 211, 1688, 2, 143, 99, 331, 267, 181, 211, 1137, 1909, 33, 234, 5, 53, 996, 131, 35, 25, 70, 356, 5, 1, 53, 223, 489, 15, 99, 135, 2020, 1, 10, 19, 42, 91, 47, 355, 618, 543, 330, 186, 472, 2, 1223, 3, 47, 618, 27, 223, 25, 28, 241, 62, 79, 3648, 2, 1, 27, 4, 356, 24, 1, 520, 3, 14, 49, 100, 8, 12945, 52, 5116, 12202, 247, 47, 1084, 800, 1521, 2, 7215, 42, 91, 1043, 1575, 216, 1302, 183, 5, 5356, 30, 8529, 1591, 356, 24, 1, 48, 3, 20, 2481, 52, 5201, 12180, 51, 434, 216, 52, 4456, 12548, 51, 3415, 147, 133, 7, 20, 79, 601, 326, 215, 8, 1112, 637, 344, 266, 1447, 306, 974, 6, 1371, 53, 246, 819, 155, 103, 8, 152, 522, 1851, 128, 47, 280, 103, 1043, 1575, 8, 3461, 271, 47, 1261, 195, 8, 898, 1084, 2906, 2, 963, 12, 1084, 7360, 3, 1, 47, 1084, 20, 50, 857, 9, 34, 2128, 974, 134, 90, 448, 13, 37, 3073, 507, 859, 2008, 602, 9, 859, 34, 237, 7, 1524, 5, 29, 439, 211, 10, 126, 19, 586, 7, 88, 529, 9, 13, 37, 1290, 760, 9, 13, 37, 75, 9, 13, 34, 99, 1465, 60, 859, 413, 470, 99, 497, 60, 859, 346, 846, 9, 13, 37, 3124, 9, 13, 1229, 697, 90, 448, 34, 2050, 9, 13, 34, 2, 88, 9, 13, 346, 237, 7, 1524, 221, 5, 55, 8, 92, 187, 174, 1, 10, 49, 100, 69, 8, 52, 5903, 156, 13881, 12, 90, 5, 108, 80, 8, 52, 13457, 51, 434, 216, 7, 17, 78, 8, 52, 6909, 27157, 51, 25016, 7, 17, 78, 2, 52, 8472, 23935, 7, 17, 78, 178, 42, 1, 10, 19, 231, 178, 2, 15, 1808, 2428, 19, 15, 1012, 6278, 22507, 299, 164, 480, 5345, 22676, 36, 633, 619, 1856, 817, 154, 24, 15419, 5615, 118, 9505, 8472, 7473, 465, 340, 134, 137]\n",
      "torch.Size([1416, 300])\n",
      "['with', 'ejection', 'fraction', 'of', 'to', 'who', 'present', 'from', 'clinic', 'with', 'a', 'chief', 'complaint', 'of', 'fatigue', 'and', 'weakness', 'for', 'one', 'week', 'she', 'had', 'had', 'worsening', 'right', 'groin', 'and', 'hip', 'pain', 'status', 'post', 'a', 'total', 'hip', 'replacement', 'approximately', 'year', 'ago', 'which', 'had', 'been', 'worsening', 'for', 'two', 'week', 'and', 'she', 'ha', 'also', 'recently', 'completed', 'a', 'course', 'of', 'levaquin', 'for', 'urinary', 'tract', 'infection', 'she', 'presented', 'to', 'dr', 'parrent', 'office', 'complaining', 'of', 'fatigue', 'and', 'weakness', 'for', 'one', 'week', 'she', 'ha', 'had', 'some', 'abdominal', 'pain', 'in', 'a', 'bandlike', 'distribution', 'around', 'her', 'right', 'side', 'she', 'wa', 'found', 'to', 'have', 'a', 'hematocrit', 'of', 'down', 'from', 'eight', 'day', 'ago', 'and', 'wa', 'sent', 'to', 'the', 'emergency', 'department', 'for', 'transfusion', 'and', 'workup', 'of', 'her', 'anemia', 'preadmission', 'medication', 'caltrate', 'plus', 'd', 'one', 'tab', 'po', 'bid', 'lantus', 'unit', 'sc', 'qpm', 'novolog', 'unit', 'unit', 'unit', 'sc', 'tid', 'imdur', 'mg', 'bid', 'amlodipine', 'mg', 'bid', 'furosemide', 'mg', 'daily', 'valsartan', 'mg', 'daily', 'warfarin', 'mg', 'daily', 'iron', 'sulfate', 'mg', 'po', 'daily', 'and', 'multivitamin', 'daily', 'past', 'medical', 'history', 'chronic', 'kidney', 'disease', 'presumed', 'due', 'to', 'congestive', 'heart', 'failurediuresisrenal', 'artery', 'diseaseearly', 'diabetic', 'nephropathy', 'type', 'diabetes', 'previous', 'stroke', 'congestive', 'heart', 'failure', 'with', 'ejection', 'fraction', 'of', 'to', 'rheumatic', 'valvular', 'disease', 'with', 'mitral', 'valve', 'replacement', 'and', 'tricuspid', 'valve', 'repair', 'atrial', 'fibrillation', 'history', 'of', 'small', 'bowel', 'obstruction', 'status', 'post', 'right', 'total', 'hip', 'replacement', 'approximately', 'year', 'ago', 'family', 'history', 'no', 'family', 'history', 'of', 'kidney', 'disease', 'or', 'heart', 'disease', 'social', 'history', 'she', 'ha', 'child', 'life', 'alone', 'with', 'home', 'care', 'in', 'me', 'but', 'ha', 'moved', 'in', 'to', 'live', 'with', 'her', 'daughter', 'in', 'news', 'irv', 'in', 'she', 'denies', 'tobacco', 'use', 'and', 'drink', 'alcohol', 'rarely', 'allergy', 'codeine', 'and', 'benadryl', 'admission', 'physical', 'examination', 'vital', 'sign', 'were', 'temperature', 'heart', 'rate', 'blood', 'pressure', 'respiration', 'and', 'sao', 'on', 'room', 'air', 'the', 'patient', 'is', 'a', 'frail', 'elderly', 'woman', 'in', 'no', 'acute', 'distress', 'she', 'ha', 'poor', 'dentition', 'jvp', 'is', 'difficult', 'to', 'ass', 'secondary', 'to', 'tricuspid', 'regurgitation', 'lung', 'were', 'clear', 'to', 'auscultation', 'bilaterally', 'cardiovascular', 'exam', 'showed', 'bradycardia', 'with', 'heart', 'rate', 'in', 'the', 's', 'that', 'wa', 'irregular', 's', 'plus', 's', 'with', 'systolic', 'murmur', 'heard', 'throughout', 'with', 'mechanical', 'sounding', 's', 'abdomen', 'wa', 'mildly', 'tender', 'to', 'palpation', 'in', 'the', 'mid', 'epigastrium', 'with', 'no', 'rebound', 'or', 'guarding', 'extremity', 'showed', 'venous', 'stasis', 'change', 'in', 'her', 'lower', 'extremity', 'bilaterally', 'foot', 'were', 'cool', 'with', 'diminished', 'dp', 'and', 'pt', 'pulse', 'on', 'neurological', 'exam', 'she', 'wa', 'alert', 'and', 'oriented', 'x', 'and', 'cranial', 'nerve', 'ii', 'through', 'xii', 'were', 'intact', 'study', 'ekg', 'showed', 'atrial', 'fibrillation', 'with', 'slow', 'ventricular', 'response', 'with', 'heart', 'rate', 'of', 'widened', 'qrs', 'a', 'q', 'wave', 'in', 'avl', 'and', 'u', 'wave', 'in', 'the', 'lateral', 'lead', 'chest', 'xray', 'showed', 'improved', 'pleural', 'effusion', 'and', 'pulmonary', 'edema', 'stable', 'marked', 'cardiomegaly', 'xray', 'of', 'the', 'right', 'hip', 'showed', 'status', 'post', 'right', 'total', 'hip', 'arthroplasty', 'with', 'stable', 'periprosthetic', 'lucency', 'and', 'cortical', 'remodeling', 'severe', 'left', 'hip', 'osteoarthritis', 'diffuse', 'atherosclerosis', 'egd', 'on', 'showed', 'hiatal', 'hernia', 'fundic', 'polyp', 'with', 'pathology', 'showing', 'hypoplastic', 'and', 'inflammatory', 'lesion', 'mild', 'antral', 'erosion', 'with', 'pathology', 'demonstrating', 'mild', 'regeneration', 'that', 'wa', 'nonspecific', 'and', 'no', 'h', 'pylorus', 'and', 'duodenitis', 'with', 'pathology', 'showing', 'normal', 'mucosa', 'but', 'no', 'active', 'bleeding', 'or', 'sign', 'of', 'recent', 'bleeding', 'capsule', 'endoscopy', 'on', 'showed', 'a', 'healing', 'gastric', 'ulcer', 'likely', 'in', 'the', 'antrum', 'small', 'bowel', 'lymphangiectasia', 'and', 'angioectasia', 'in', 'the', 'distal', 'small', 'bowel', 'colonoscopy', 'on', 'demonstrated', 'cecal', 'diverticulum', 'approximately', 'mm', 'ascending', 'sessile', 'polyp', 'and', 'several', 'small', 'sessile', 'polyp', 'in', 'the', 'rectosigmoid', 'procedure', 'right', 'basilic', 'vein', 'transposition', 'on', 'by', 'dr', 'jacinto', 'goonez', 'hospital', 'course', 'by', 'problem', 'gi', 'bleed', 'in', 'the', 'emergency', 'department', 'the', 'patient', 'vital', 'sign', 'were', 'temperature', 'heart', 'rate', 'respiration', 'blood', 'pressure', 'with', 'sao', 'on', 'room', 'air', 'she', 'wa', 'found', 'to', 'have', 'black', 'guaiac', 'positive', 'stool', 'and', 'gi', 'wa', 'consulted', 'she', 'wa', 'started', 'on', 'iv', 'nexium', 'mg', 'bid', 'and', 'wa', 'given', 'vitamin', 'k', 'mg', 'subcutaneously', 'and', 'two', 'unit', 'of', 'ffp', 'and', 'she', 'wa', 'transfused', 'three', 'unit', 'of', 'packed', 'red', 'blood', 'cell', 'with', 'lasix', 'mg', 'iv', 'for', 'each', 'bag', 'of', 'note', 'the', 'patient', 'had', 'a', 'colonoscopy', 'in', 'wa', 'on', 'which', 'showed', 'bleeding', 'rectal', 'ulcer', 'with', 'biopsy', 'consistent', 'with', 'ischemic', 'colitis', 'an', 'egd', 'on', 'showed', 'a', 'hiatal', 'hernia', 'fundic', 'polyp', 'path', 'hypoplasticinflammatory', 'mild', 'antral', 'erosion', 'path', 'mild', 'regeneration', 'nonspecific', 'no', 'h', 'pylorus', 'duodenitis', 'path', 'normal', 'mucosa', 'but', 'no', 'active', 'bleeding', 'or', 'sign', 'of', 'recent', 'bleeding', 'capsule', 'endoscopy', 'on', 'showed', 'healing', 'gastric', 'ulcer', 'likely', 'in', 'the', 'antrum', 'small', 'bowel', 'lymphangiectasia', 'and', 'angioectasia', 'in', 'the', 'distal', 'small', 'bowel', 'which', 'were', 'considered', 'the', 'likely', 'source', 'of', 'bleeding', 'colonoscopy', 'wa', 'performed', 'on', 'to', 'search', 'for', 'angioectasias', 'for', 'which', 'intervention', 'would', 'be', 'possible', 'but', 'demonstrated', 'only', 'a', 'cecal', 'diverticulum', 'and', 'approximately', 'mm', 'ascending', 'sessile', 'polyp', 'and', 'several', 'small', 'sessile', 'polyp', 'in', 'the', 'rectosigmoid', 'the', 'patient', 'wa', 'started', 'on', 'aranesp', 'but', 'had', 'a', 'point', 'hematocrit', 'drop', 'from', 'to', 'on', 'for', 'which', 'she', 'required', 'another', 'two', 'unit', 'of', 'blood', 'along', 'with', 'lasix', 'the', 'patient', 'hematocrit', 'remained', 'stable', 'at', 'approximately', 'to', 'and', 'she', 'will', 'be', 'restarted', 'on', 'anticoagulation', 'on', 'thursday', 'one', 'week', 'after', 'her', 'av', 'fistula', 'surgery', 'renal', 'the', 'patient', 'ha', 'chronic', 'kidney', 'disease', 'and', 'is', 'being', 'considered', 'for', 'a', 'possible', 'hemodialysis', 'in', 'the', 'future', 'she', 'wa', 'continued', 'on', 'her', 'caltrate', 'plus', 'd', 'multivitamin', 'and', 'iron', 'supplementation', 'and', 'she', 'wa', 'started', 'on', 'aranesp', 'mcg', 'weekly', 'and', 'wa', 'given', 'sevelamer', 'mg', 'qac', 'for', 'elevated', 'phosphate', 'level', 'vein', 'mapping', 'study', 'wa', 'performed', 'on', 'and', 'a', 'right', 'basilic', 'vein', 'transposition', 'wa', 'performed', 'on', 'by', 'dr', 'landrie', 'the', 'patient', 'had', 'postoperative', 'right', 'hand', 'coolness', 'numbness', 'and', 'weakness', 'always', 'with', 'dopplerable', 'radial', 'pulse', 'from', 'steal', 'versus', 'neurapraxia', 'which', 'wa', 'improved', 'by', 'the', 'time', 'of', 'discharge', 'she', 'will', 'follow', 'up', 'with', 'dr', 'chanthasene', 'a', 'an', 'outpatient', 'the', 'patient', 'creatinine', 'wa', 'on', 'admission', 'improved', 'to', 'by', 'which', 'wa', 'the', 'day', 'of', 'her', 'surgery', 'and', 'increased', 'again', 'to', 'on', 'she', 'wa', 'given', 'iv', 'lasix', 'bolus', 'a', 'she', 'had', 'evidence', 'of', 'volume', 'overload', 'with', 'over', 'eightpound', 'weight', 'gain', 'during', 'her', 'hospitalization', 'and', 'creatinine', 'improved', 'to', 'by', 'the', 'day', 'of', 'discharge', 'cardiovascular', 'pump', 'the', 'patient', 'ejection', 'fraction', 'is', 'to', 'and', 'she', 'wa', 'given', 'mg', 'of', 'iv', 'lasix', 'for', 'each', 'unit', 'of', 'packed', 'red', 'blood', 'cell', 'she', 'received', 'along', 'with', 'mg', 'po', 'daily', 'with', 'iv', 'bolus', 'of', 'mg', 'a', 'needed', 'for', 'volume', 'overload', 'a', 'judged', 'by', 'an', 'increase', 'in', 'her', 'weight', 'antihypertensive', 'medication', 'were', 'originally', 'held', 'for', 'her', 'gi', 'bleed', 'and', 'they', 'were', 'restarted', 'on', 'with', 'systolic', 'blood', 'pressure', 'remaining', 'in', 'the', 's', 'to', 's', 'rhythm', 'the', 'patient', 'ha', 'atrial', 'fibrillation', 'with', 'slow', 'ventricular', 'response', 'with', 'heart', 'rate', 'a', 'low', 'a', 'the', 'upper', 's', 'occasionally', 'her', 'heart', 'rate', 'appeared', 'regular', 'and', 'wa', 'thought', 'to', 'be', 'junctional', 'escape', 'rhythm', 'she', 'wa', 'asymptomatic', 'throughout', 'her', 'hospitalization', 'she', 'wa', 'discussed', 'with', 'her', 'cardiologist', 'dr', 'fritz', 'who', 'will', 'consider', 'a', 'pacemaker', 'a', 'an', 'outpatient', 'endocrine', 'she', 'is', 'euthyroid', 'with', 'tsh', 'of', 'for', 'her', 'diabetes', 'she', 'received', 'nightly', 'lantus', 'with', 'aspart', 'qac', 'and', 'sliding', 'scale', 'when', 'eating', 'and', 'regular', 'insulin', 'sliding', 'scale', 'qh', 'when', 'npo', 'fingersticks', 'were', 'elevated', 'to', 's', 'early', 'during', 'this', 'admission', 'but', 'improved', 'to', 'the', 's', 'upon', 'increasing', 'her', 'insulin', 'dose', 'musculoskeletal', 'the', 'patient', 'is', 'status', 'post', 'right', 'total', 'hip', 'replacement', 'approximately', 'year', 'ago', 'and', 'complained', 'of', 'right', 'hip', 'pain', 'upon', 'admission', 'an', 'xray', 'showed', 'stable', 'arthroplasty', 'and', 'the', 'pain', 'wa', 'improved', 'by', 'the', 'morning', 'of', 'she', 'will', 'follow', 'with', 'physiatrist', 'dr', 'allan', 'kofoed', 'complication', 'right', 'hand', 'weakness', 'numbness', 'and', 'coolness', 'status', 'post', 'av', 'fistula', 'surgery', 'possibly', 'secondary', 'to', 'steal', 'or', 'neurapraxia', 'significantly', 'improved', 'by', 'the', 'time', 'of', 'discharge', 'consultant', 'dr', 'garfield', 'kiehne', 'from', 'vascular', 'surgery', 'dr', 'ambrose', 'moldrem', 'from', 'gastroenterology', 'physical', 'examination', 'on', 'discharge', 'stable', 'vital', 'sign', 'lung', 'with', 'bibasilar', 'crackle', 'systolic', 'murmur', 'heard', 'throughout', 'plus', 'a', 'mechanical', 's', 'abdomen', 'benign', 'lower', 'extremity', 'with', 'chronic', 'venous', 'stasis', 'change', 'right', 'upper', 'extremity', 'av', 'fistula', 'with', 'thrill', 'decreased', 'right', 'radial', 'pulse', 'with', 'warm', 'hand', 'distally', 'and', 'strength', 'in', 'hand', 'grip', 'of', 'the', 'right', 'hand', 'discharge', 'medication', 'norvasc', 'mg', 'daily', 'caltrate', 'plus', 'd', 'one', 'tablet', 'po', 'bid', 'aranesp', 'mcg', 'subcu', 'weekly', 'lovenox', 'mg', 'subcu', 'daily', 'starting', 'on', 'thursday', 'to', 'be', 'discontinued', 'when', 'patient', 'inr', 'is', 'therapeutic', 'on', 'coumadin', 'nexium', 'mg', 'po', 'bid', 'ferrous', 'sulfate', 'mg', 'po', 'bid', 'lasix', 'mg', 'po', 'daily', 'insulin', 'aspart', 'unit', 'subcu', 'every', 'meal', 'insulin', 'lantus', 'unit', 'subcu', 'qpm', 'imdur', 'mg', 'po', 'bid', 'sevelamer', 'mg', 'po', 'qac', 'multivitamin', 'one', 'tablet', 'daily', 'valsartan', 'mg', 'po', 'daily', 'and', 'coumadin', 'mg', 'po', 'qpm', 'starting', 'on', 'thursday', 'disposition', 'to', 'home', 'with', 'service', 'followup', 'appointment', 'the', 'patient', 'will', 'follow', 'up', 'with', 'dr', 'brendan', 'b', 'tordsen', 'in', 'one', 'to', 'two', 'week', 'with', 'dr', 'schaetzle', 'from', 'vascular', 'surgery', 'on', 'at', 'am', 'with', 'dr', 'salvatore', 'sherrod', 'from', 'physiatry', 'on', 'at', 'am', 'and', 'dr', 'margarito', 'nolting', 'on', 'at', 'am', 'code', 'status', 'the', 'patient', 'is', 'full', 'code', 'and', 'her', 'healthcare', 'proxy', 'is', 'her', 'daughter', 'shane', 'lutao', 'primary', 'care', 'physician', 'rufus', 'mannheimer', 'md', 'escription', 'document', 'cssten', 'tel', 'dictated', 'by', 'beier', 'julio', 'attending', 'hambric', 'margarito', 'kurt', 'dictation', 'id', 'd', 't']\n",
      "torch.Size([1416, 300])\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import vocab\n",
    "\n",
    "vec = torchtext.vocab.FastText()\n",
    "\n",
    "one_hot_test = all_df_expanded.iloc[0]['one_hot']\n",
    "\n",
    "print(one_hot_test)\n",
    "ret = vec.get_vecs_by_tokens(voc.lookup_tokens(one_hot_test))\n",
    "print(ret.shape)\n",
    "print(vector_tokenized_test)\n",
    "ret = vec.get_vecs_by_tokens(vector_tokenized_test)\n",
    "print(ret.shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "10pK5od01jfTHJyLN94dJxEube3sJszFm",
     "timestamp": 1678482671183
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
