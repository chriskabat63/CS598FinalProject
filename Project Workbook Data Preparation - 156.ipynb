{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d1ehXFWM5aE"
   },
   "source": [
    "This notebook was created to support the data preparation required to support our CS 598 DLH project.  The paper we have chosen for the reproducibility project is:\n",
    "***Ensembling Classical Machine Learning and Deep Learning Approaches for Morbidity Identification from Clinical Notes ***\n",
    "\n",
    "Abstract:  The main goal of the paper is to extract Morbidity from clinical notes.  The idea was to use a combination of classical and deep learning methods to determine the best approach for classifying these notes in one or more of 16 morbidity conditions.  These models used a combination of NLP techniques including embeddings and bag of words implementations.  It also measured the effect including of stop words.  Lastly, it used ensemble techniques to tie together a number of the classical and deep learning models to provide the most accurate results.\n",
    "\n",
    "Dataset was retrieved from the DBMI Data Portal, Department of Biomedical Informatics (DBMI) in the Blavatnik Institute at Harvard Medical School.  This dataset was originally created for the i2b2 Obesity Challenge conducted in 2008.\n",
    "This data was provided in XML format with a test and training set.  Along with the test and training set, labeled data of two forms were included. They were called Intuitive and Textual.  Textual judgements were derived by looking at the notes by multiple experts.  When the experts didnâ€™t agree, a resident doctor annotated it with a Intuitive judgement.\n",
    "\n",
    "In this workbook, we are taking the following steps:\n",
    "\n",
    "\n",
    "* Loading test and train data along with annotations\n",
    "* Exploring the best annotation data sets to use\n",
    "* Preprocessing the data using NLP techniques described below.\n",
    "* Saving the data as pkl files for use in additional notebooks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4130,
     "status": "ok",
     "timestamp": 1679769726172,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "abcc0TyDkN4r",
    "outputId": "12bdbdd7-6ffe-48fd-9800-bb5895f0b1e2"
   },
   "outputs": [],
   "source": [
    "pip install xmltodict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv360l2IkNfO"
   },
   "source": [
    "The data cannot be shared publicly due to the agreements required to obtain the data so we are storing the data locally and not putting in GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1250,
     "status": "ok",
     "timestamp": 1679769727418,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "zyXrAo2dsJqf",
    "outputId": "0cc91c5b-f4de-41e2-f2bd-dd9ca70041a3"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = './obesity_data/'\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cw_odcoTOTS-"
   },
   "source": [
    "Next we create a function to load the data from XML files and convert to a more usable dataframe structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1679769727418,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "AKAxFxOCMadc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xmltodict\n",
    "\n",
    "def load_dataset(filepath, xpath):    \n",
    "    return pd.read_xml(filepath, xpath=xpath)\n",
    "\n",
    "def load_annotations(filepath):\n",
    "\n",
    "  with open(filepath,\"r\") as f:\n",
    "      data = f.read()\n",
    "\n",
    "  df = pd.DataFrame(columns=['source','disease','id','judgment'])\n",
    "\n",
    "  data = xmltodict.parse(data)['diseaseset']['diseases']\n",
    "\n",
    "  for key,val in enumerate(data):\n",
    "    if(isinstance(val,str)):\n",
    "      source = data['@source']\n",
    "      disease = data['disease']\n",
    "    else:\n",
    "      source = val['@source']\n",
    "      disease = val['disease']\n",
    "\n",
    "    for key,val in enumerate(disease):\n",
    "      if(isinstance(val,str)):\n",
    "        disease_name = disease['@name']\n",
    "        doc = disease['doc']\n",
    "      else:\n",
    "        disease_name = val['@name']\n",
    "        doc = val['doc']\n",
    "      \n",
    "      for key,val in enumerate(doc):\n",
    "        if(isinstance(val,str)):\n",
    "          doc_id = doc['@id']\n",
    "          judgment = doc['@judgment']\n",
    "        else:\n",
    "          doc_id = val['@id']\n",
    "          judgment = val['@judgment']\n",
    "        df_temp = pd.DataFrame([{\"source\":source,\"disease\":disease_name,\"id\":doc_id,\"judgment\":judgment}])\n",
    "        #df = df.append(df_temp)  \n",
    "        df = pd.concat([df,df_temp])\n",
    "\n",
    "  #The xml acts really strange if there are single nodes.  Dropping duplicates solves it.\n",
    "  return df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLs0aX04OgNn"
   },
   "source": [
    "Now we load the test and train datasets and examine the notes. Note, we are loading the training file with 2 as a seperate data frame as it relates to all the addendums which we believe was not used by the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1679769727568,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "yq2MgXu1naLN",
    "outputId": "3cfb3f54-e246-4b7a-9799-15701ee92f28"
   },
   "outputs": [],
   "source": [
    "test_df = load_dataset(DATA_PATH + 'obesity_patient_records_test.xml', xpath='/root/docs/*')\n",
    "test_df['id'] = pd.to_numeric(test_df['id'])\n",
    "print(test_df.head())\n",
    "print(len(test_df))\n",
    "\n",
    "train_df = load_dataset(DATA_PATH + 'obesity_patient_records_training.xml', xpath='/root/docs/*')\n",
    "train_df_with2 = train_df.append(load_dataset(DATA_PATH + '/obesity_patient_records_training2.xml', xpath='/root/docs/*'))\n",
    "train_df['id'] = pd.to_numeric(train_df['id'])\n",
    "train_df_with2['id'] = pd.to_numeric(train_df_with2['id'])\n",
    "print(train_df.head())\n",
    "print(len(train_df))\n",
    "print(len(train_df_with2))\n",
    "\n",
    "print(test_df['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACBjTAgsOmgT"
   },
   "source": [
    "The annotation data came in two forms: textual and intuitive.  It also came with files with the forms in seperate files and with the forms all together in one file.  We do some exploration to determine which set of data is the closest to the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27805,
     "status": "ok",
     "timestamp": 1679769755372,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "Mlf84b2lhh9x",
    "outputId": "cc2b826a-e08a-43a6-9269-9ee9549d590c"
   },
   "outputs": [],
   "source": [
    "test_annot_intuitive_df = load_annotations(DATA_PATH + \"obesity_standoff_annotations_test_intuitive.xml\")\n",
    "test_annot_intuitive_df['id'] = pd.to_numeric(test_annot_intuitive_df['id'])\n",
    "\n",
    "test_annot_textual_df = load_annotations(DATA_PATH + \"obesity_standoff_annotations_test_textual.xml\")\n",
    "test_annot_textual_df['id'] = pd.to_numeric(test_annot_textual_df['id'])\n",
    "\n",
    "print(test_annot_intuitive_df.head())\n",
    "print(len(test_annot_intuitive_df))\n",
    "\n",
    "print(test_annot_textual_df.head())\n",
    "print(len(test_annot_textual_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlDvN-LnPLwl"
   },
   "source": [
    "The test file with all forms is explored and the record count seems the same as combining the seperate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1679769767321,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "u8Y_KX0h1Jsn",
    "outputId": "c37da12d-1e5e-4ca9-ad59-f90251686ecd"
   },
   "outputs": [],
   "source": [
    "#trying to verify the same number of records in the one with both intuitive and textual\n",
    "test_annot_all_df = load_annotations(DATA_PATH + \"obesity_standoff_annotations_test.xml\")\n",
    "test_annot_all_df['id'] = pd.to_numeric(test_annot_all_df['id'])\n",
    "\n",
    "print(test_annot_all_df.head())\n",
    "print(len(test_annot_all_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR_EMmuoPSf0"
   },
   "source": [
    "We then do the same analysis with the training annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29125,
     "status": "ok",
     "timestamp": 1679769796436,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "1nUpoSeuxMDG",
    "outputId": "0ed999c6-111d-4aa8-b988-2e1bf6f6e468"
   },
   "outputs": [],
   "source": [
    "train_annot_intuitive_df = load_annotations(DATA_PATH + \"obesity_standoff_intuitive_annotations_training.xml\")\n",
    "train_annot_intuitive_df['id'] = pd.to_numeric(train_annot_intuitive_df['id'])\n",
    "train_annot_textual_df = load_annotations(DATA_PATH + \"obesity_standoff_textual_annotations_training.xml\")\n",
    "train_annot_textual_df['id'] = pd.to_numeric(train_annot_textual_df['id'])\n",
    "\n",
    "print(train_annot_intuitive_df.head())\n",
    "print(len(train_annot_intuitive_df))\n",
    "\n",
    "print(train_annot_textual_df.head())\n",
    "print(len(train_annot_textual_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM3B1QR-PWsq"
   },
   "source": [
    "When we look at the full file with addendums, we see there is a lot more data in the full file than the seperate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18423,
     "status": "ok",
     "timestamp": 1679769814849,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "Qrh6CrnzC1P8",
    "outputId": "bda08ef8-49ef-4b81-ccfa-bb9fb8d8ead2"
   },
   "outputs": [],
   "source": [
    "#trying to verify the same number of records in the one with both intuitive and textual (It isn't according to tally.pdf it should be 22285 with the annotations and addendums)\n",
    "train_annot_all_df = load_annotations(DATA_PATH + \"obesity_standoff_annotations_training.xml\")\n",
    "train_annot_all_df_with2 = pd.concat([train_annot_all_df,load_annotations(DATA_PATH + \"obesity_standoff_annotations_training_addendum.xml\")])\n",
    "train_annot_all_df_with2 = pd.concat([train_annot_all_df_with2,load_annotations(DATA_PATH + \"obesity_standoff_annotations_training_addendum2.xml\")])\n",
    "train_annot_all_df_with2 = pd.concat([train_annot_all_df_with2,load_annotations(DATA_PATH + \"obesity_standoff_annotations_training_addendum3.xml\")])\n",
    "\n",
    "train_annot_all_df['id'] = pd.to_numeric(train_annot_all_df['id'])\n",
    "train_annot_all_df_with2['id'] = pd.to_numeric(train_annot_all_df_with2['id'])\n",
    "\n",
    "print(train_annot_all_df.head())\n",
    "print(len(train_annot_all_df))\n",
    "print(len(train_annot_all_df_with2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFn3q_Fom9T6"
   },
   "source": [
    "We are going to start with the annotations in one file (test_annot_all_df, train_annot_all_df).  The paper only used annotations that were clearly marked 'Y' or 'N' (It excluded the 'Q' and 'U')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1679769814849,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "QfHtYhyrm8zP",
    "outputId": "459aaf55-69d9-4eae-e8d0-0627249da20a"
   },
   "outputs": [],
   "source": [
    "print(len(test_annot_all_df),len(train_annot_all_df))\n",
    "test_annot_all_df_clean = test_annot_all_df[(test_annot_all_df['judgment']  == 'Y') | (test_annot_all_df['judgment']  == 'N')]\n",
    "train_annot_all_df_clean = train_annot_all_df[(train_annot_all_df['judgment']  == 'Y') | (train_annot_all_df['judgment']  == 'N')]\n",
    "print(len(test_annot_all_df_clean),len(train_annot_all_df_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679769814849,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "PHKozf15u2Km",
    "outputId": "b5719f17-543c-4fbd-f325-cda401b40043"
   },
   "outputs": [],
   "source": [
    "print(test_annot_all_df_clean.groupby('disease').size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679769814850,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "WUVhK8bkvbXV",
    "outputId": "5d03131a-d4af-49a4-f452-9e62c6cfd92b"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(train_annot_all_df_clean.groupby('disease').size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfezONE45GEd"
   },
   "source": [
    "The paper specifically calls out 6 files and does not mention the addendums, so we will stick with the seperately labeled files for our study. There seems to be only one record in each of the test and training set where the textual and intuitive disagree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1679769814850,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "EkckqW7G0Fqh",
    "outputId": "5dca85d7-49c8-46a3-fed8-031958afe016"
   },
   "outputs": [],
   "source": [
    "test_annot_intuitive_df_clean = test_annot_intuitive_df[(test_annot_intuitive_df['judgment']  == 'Y') | (test_annot_intuitive_df['judgment']  == 'N')]\n",
    "test_annot_textual_df_clean = test_annot_textual_df[(test_annot_textual_df['judgment']  == 'Y') | (test_annot_textual_df['judgment']  == 'N')]\n",
    "train_annot_intuitive_df_clean = train_annot_intuitive_df[(train_annot_intuitive_df['judgment']  == 'Y') | (train_annot_intuitive_df['judgment']  == 'N')]\n",
    "train_annot_textual_df_clean = train_annot_textual_df[(train_annot_textual_df['judgment']  == 'Y') | (train_annot_textual_df['judgment']  == 'N')]\n",
    "\n",
    "print(len(test_annot_intuitive_df_clean))\n",
    "print(len(test_annot_textual_df_clean))\n",
    "\n",
    "\n",
    "df = test_annot_intuitive_df_clean.merge(test_annot_textual_df_clean, on=['id','disease'])\n",
    "print(df[df['judgment_x'] != df['judgment_y']])\n",
    "\n",
    "print(len(train_annot_intuitive_df_clean))\n",
    "print(len(train_annot_textual_df_clean))\n",
    "\n",
    "df = train_annot_intuitive_df_clean.merge(train_annot_textual_df_clean, on=['id','disease'])\n",
    "print(df[df['judgment_x'] != df['judgment_y']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Z9joC8e-aFl"
   },
   "source": [
    "Let's remove those two records from the textual table and recheck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1679769814851,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "YfspC1q0-lUU",
    "outputId": "301372e0-0415-4a60-b5fd-91b5d8fd8490"
   },
   "outputs": [],
   "source": [
    "df = test_annot_textual_df_clean\n",
    "df = df.reset_index()\n",
    "index_names = df[(df['disease'] == 'OA') & (df['id'] == 8)].index\n",
    "test_annot_textual_df_clean = df.drop(index_names)\n",
    "\n",
    "df = train_annot_textual_df_clean\n",
    "df = df.reset_index()\n",
    "index_names = df[(df['disease'] == 'CHF') & (df['id'] == 1072)].index\n",
    "train_annot_textual_df_clean = df.drop(index_names)\n",
    "\n",
    "print(len(test_annot_textual_df_clean))\n",
    "df = test_annot_intuitive_df_clean.merge(test_annot_textual_df_clean, on=['id','disease'])\n",
    "print(df[df['judgment_x'] != df['judgment_y']])\n",
    "\n",
    "print(len(train_annot_textual_df_clean))\n",
    "df = train_annot_intuitive_df_clean.merge(train_annot_textual_df_clean, on=['id','disease'])\n",
    "print(df[df['judgment_x'] != df['judgment_y']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDoDyp5u9uSA"
   },
   "source": [
    "The paper does a classification model for each disase seperately.  Need to be able to loop through each. Using the seperate files  seems to come closer to the disease counts the paper discusses before pre-processing, so we will use this data. The study must have done some additional processing that is not evident from the paper, so our results may be a little different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1679769815355,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "l0WT-GUr5o7o",
    "outputId": "1eee01bd-aa4b-4f0b-cda3-63ede6c3a392"
   },
   "outputs": [],
   "source": [
    "disease_list = train_annot_intuitive_df_clean['disease'].unique().tolist()\n",
    "\n",
    "train_annot_all_df_clean = pd.concat([train_annot_intuitive_df_clean,train_annot_textual_df_clean])\n",
    "train_annot_all_df_clean = train_annot_all_df_clean.drop(['source','index'], axis=1)\n",
    "train_annot_all_df_clean = train_annot_all_df_clean.drop_duplicates()\n",
    "\n",
    "test_annot_all_df_clean = pd.concat([test_annot_intuitive_df_clean,test_annot_textual_df_clean])\n",
    "test_annot_all_df_clean = test_annot_all_df_clean.drop(['source','index'], axis=1)\n",
    "test_annot_all_df_clean = test_annot_all_df_clean.drop_duplicates()\n",
    "\n",
    "annot_all_df_clean = pd.concat([train_annot_all_df_clean,test_annot_all_df_clean])\n",
    "annot_all_df_clean = annot_all_df_clean.drop_duplicates()\n",
    "samples = 0\n",
    "\n",
    "for disease in disease_list:\n",
    "  print('Disease:',disease)\n",
    "  print('Train:',sum(train_annot_intuitive_df_clean['disease'] == disease),\n",
    "        sum(train_annot_textual_df_clean['disease'] == disease),\n",
    "        sum(train_annot_all_df_clean['disease'] == disease))\n",
    "  print('Test:',sum(test_annot_intuitive_df_clean['disease'] == disease),\n",
    "        sum(test_annot_textual_df_clean['disease'] == disease),\n",
    "        sum(test_annot_all_df_clean['disease'] == disease))  \n",
    "  print('All:',sum(annot_all_df_clean['disease'] == disease))\n",
    "  samples = sum(annot_all_df_clean['disease'] == disease) + samples\n",
    "\n",
    "print(\"Samples:\",samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allannot_df = pd.concat([train_annot_all_df_clean,test_annot_all_df_clean])\n",
    "alldocs_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VmV5x9WQfZ3"
   },
   "source": [
    "Datasets to use for rest of the study:\n",
    "* alldocs_df [id,text] (document, clinical notes)\n",
    "* allannot_df [disease,id,judment,index] (disease, document, judgment)\n",
    "\n",
    "For the annotations, we should convert judgement to a numeric label.\n",
    "\n",
    "Our next step is to continue the preprocessing of the data.  We want to do this seperately from the annotations, they can be joined when doing classification by each disase. This includes:\n",
    "\n",
    "* Lower-casing of the text\n",
    "* Removing punctuation and numeric values from the text\n",
    "* Tokenization of text \n",
    "* Lemmatizattion of the tokens\n",
    "* TF-IDF matrix generation (TF-IDF Vectorizer4 from the scikit-learn library)\n",
    "\n",
    "We have an optional parameter to remove stop words as the paper discusses the fact that stop words should be included for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Y/N to True/False\n",
    "#test_annot_all_df_clean['judgment'] = test_annot_all_df_clean['judgment'] == 'Y'\n",
    "#train_annot_all_df_clean['judgment'] = train_annot_all_df_clean['judgment'] == 'Y'\n",
    "allannot_df['judgment'] = allannot_df['judgment'] == 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1679770827175,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "zkGLF2yPfdnJ",
    "outputId": "c37191e4-cae7-4573-f6f0-8328570c055b"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "wn = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "vectorizer = TfidfVectorizer(stop_words = cachedStopWords, max_features = 600)\n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "# add param above: vocabulary=custom_vocab , where custom_vocab is the vocabulary of\n",
    "# ranked features selected by applying the feature selection algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanword(word):\n",
    "    word = word.lower()\n",
    "\n",
    "    word = ''.join([i for i in word if not i.isdigit()])\n",
    "    symbols = \"|,!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    word = word.translate(str.maketrans('', '', symbols))\n",
    "    word = stemmer.stem(word)\n",
    "    word = wn.lemmatize(word)\n",
    "\n",
    "    return word\n",
    "\n",
    "def cleansentence(sentence):\n",
    "    sentence = ' '.join([cleanword(word) for word in sentence.split()])\n",
    "    sentence = re.sub(' +', ' ', sentence).strip()\n",
    "    return sentence\n",
    "\n",
    "\n",
    "##Sentences - we can't do data cleansing until after sentence tokenized\n",
    "alldocs_df['sentence_tokenized'] = alldocs_df['text'].replace(\"\\n\", \"\")\n",
    "alldocs_df['sentence_tokenized'] = alldocs_df['sentence_tokenized'].apply(lambda x: sent_tokenize(x)) # this is a list of sentences\n",
    "alldocs_df['sentence_tokenized'] = alldocs_df['sentence_tokenized'].apply(lambda lst:[cleansentence(sentence) for sentence in lst]) # this is a list of sentences\n",
    "\n",
    "##Trying a different approach to cleansing for embeddings, treat text as one big sentence\n",
    "alldocs_df['word_tokenized'] = alldocs_df['text'].replace(\"\\n\", \"\")\n",
    "alldocs_df['word_tokenized'] = alldocs_df['word_tokenized'].apply(lambda x: cleansentence(x))\n",
    "alldocs_df['word_tokenized'] = alldocs_df.apply(lambda row: word_tokenize(row['word_tokenized']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4057,
     "status": "ok",
     "timestamp": 1679771153404,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "Gw14Xn7zDL_e",
    "outputId": "ea3aafa5-c429-4456-aeeb-1ddd58c42f52"
   },
   "outputs": [],
   "source": [
    "def preparetext(df, removestopwords = False):\n",
    "\n",
    "    ndf = df.copy()\n",
    "\n",
    "    ndf[\"no_punc_text\"] = ndf['text'].str.replace('[^\\w\\s]', '')\n",
    "    ndf[\"no_numerics_text\"] = ndf['no_punc_text'].str.replace('\\d+', '')\n",
    "    ndf[\"lower_text\"] = ndf['no_numerics_text'].apply(str.lower)\n",
    "\n",
    "    #this has a side effect of getting rid of all of the carriage returns, etc.\n",
    "    if removestopwords:\n",
    "         ndf['lower_text'] =  ndf['lower_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (cachedStopWords)]))\n",
    "    else:\n",
    "         ndf['lower_text'] =  ndf['lower_text'].apply(lambda x: ' '.join([word for word in x.split()]))\n",
    "\n",
    "    ndf[\"tokenized_text\"] = ndf.apply(lambda row: word_tokenize(row['lower_text']), axis=1)\n",
    "\n",
    "    ndf[\"tok_lem_text\"] = ndf['tokenized_text'].apply(\n",
    "        lambda lst:[wn.lemmatize(word) for word in lst])\n",
    "    \n",
    "    #X = vectorizer.fit_transform(ndf['lower_text'])\n",
    "    #print(X[0])\n",
    "\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create seperate dataframes with stop words included and removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1679771153404,
     "user": {
      "displayName": "Matthew Lopes",
      "userId": "01980291092524472313"
     },
     "user_tz": 240
    },
    "id": "QQbaVExOGyoP",
    "outputId": "763849da-e152-4b63-9625-607f50c63981"
   },
   "outputs": [],
   "source": [
    "alldocs_df = preparetext(alldocs_df, removestopwords=False)\n",
    "#print(alldocs_df['tok_lem_text'][0])\n",
    "alldocs_df_ns = preparetext(alldocs_df, removestopwords=True)\n",
    "#print(alldocs_df_ns['tok_lem_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_selection(df):\n",
    "    # apply ExtraTreesClassifier\n",
    "    #extra_tree_feature_selection = clf.\n",
    "    \n",
    "    # apply InfoGainAttributeEval\n",
    "    \n",
    "    # apply SelectKBest\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    X = vectorizer.fit_transform(df['lower_text'])\n",
    "    #print(X[0])\n",
    "    print(X.shape) # For DL models needs to be dimension {n x 600}, with n the number of text documents (clinical records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save each of these data frames for use in future notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.to_pickle(DATA_PATH + '/test_df.pkl')\n",
    "#train_df.to_pickle(DATA_PATH + '/train_df.pkl')\n",
    "#test_df_ns.to_pickle(DATA_PATH + '/test_df_ns.pkl') \n",
    "#train_df_ns.to_pickle(DATA_PATH + '/train_df_ns.pkl')\n",
    "#test_annot_all_df_clean.to_pickle(DATA_PATH + '/test_annot_all_df_clean.pkl') \n",
    "#train_annot_all_df_clean.to_pickle(DATA_PATH + '/train_annot_all_df_clean.pkl') \n",
    "\n",
    "alldocs_df.to_pickle(DATA_PATH + '/alldocs_df.pkl')\n",
    "alldocs_df_ns.to_pickle(DATA_PATH + '/alldocs_df_ns.pkl')\n",
    "allannot_df.to_pickle(DATA_PATH + '/allannot_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "10pK5od01jfTHJyLN94dJxEube3sJszFm",
     "timestamp": 1678482671183
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
